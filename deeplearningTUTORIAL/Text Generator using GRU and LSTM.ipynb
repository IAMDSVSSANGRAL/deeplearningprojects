{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f88680c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "faqs = \"\"\"About Disney World\n",
    "What is the entrance fee for Disney World in 2023?\n",
    "Disney World tickets vary in price depending on the date and the type of ticket. Single-day tickets start at $109 for adults.\n",
    "What is the total duration for a typical Disney World visit?\n",
    "A typical visit to Disney World can range from a single day to a week, with 4 to 7 days being ideal to experience most attractions.\n",
    "What are the main attractions at Disney World?\n",
    "Disney World features the following key attractions:\n",
    "Magic Kingdom\n",
    "Epcot\n",
    "Disney's Hollywood Studios\n",
    "Disney's Animal Kingdom\n",
    "Water Parks: Blizzard Beach and Typhoon Lagoon\n",
    "Disney Springs for shopping and dining\n",
    "Numerous resorts and hotels\n",
    "You can check the detailed attractions list here - https://disneyworld.disney.go.com/\n",
    "Is the Star Wars: Galaxy's Edge part of Disney World?\n",
    "Yes, Star Wars: Galaxy's Edge is located in Disney's Hollywood Studios.\n",
    "What if I miss a reservation for a popular ride? Can I get another chance?\n",
    "Yes, you can use the Disney Genie+ service to book reservations for popular rides and attractions throughout the day.\n",
    "Where can I find the schedule for parades and fireworks?\n",
    "Check the official Disney World app or website for up-to-date schedules for parades and fireworks.\n",
    "How long do parades and fireworks last?\n",
    "Parades typically last about 30 minutes, and fireworks shows last around 15 to 20 minutes.\n",
    "What languages are spoken by the staff at Disney World?\n",
    "Staff at Disney World speak English, but you can find guides and services in multiple languages.\n",
    "How will I be informed about changes in park hours or attractions?\n",
    "You will get updates through the official Disney World app and website.\n",
    "Can I visit Disney World if I have mobility issues?\n",
    "Yes, Disney World is equipped with facilities and services to assist guests with mobility issues.\n",
    "Can I enter Disney World in the middle of the day?\n",
    "Yes, your ticket allows you to enter Disney World at any time during the park's operating hours.\n",
    "If I leave the park, can I re-enter on the same day?\n",
    "Yes, you can re-enter the park on the same day as long as you have a valid ticket and hand stamp.\n",
    "Are there any educational programs at Disney World?\n",
    "Yes, Disney World offers several educational programs and tours for all age groups.\n",
    "Where can I contact Disney World for more information?\n",
    "You can call Disney World Guest Services at (407) 939-5277 or visit their website.\n",
    "Payment and Ticket Queries\n",
    "Where do we purchase tickets for Disney World? Can we buy them on YouTube or your website?\n",
    "Tickets should be purchased through the official Disney World website or authorized sellers.\n",
    "Can we pay for multiple days in advance?\n",
    "Yes, you can purchase multi-day tickets in advance, which often come with discounts.\n",
    "What is the validity of a multi-day ticket? If I start using it on January 15, when do I have to use the remaining days?\n",
    "Multi-day tickets are valid for a specific period, usually within 14 days of the first use. Check the details when purchasing.\n",
    "What if I don't enjoy Disney World after purchasing a ticket? What is the refund policy?\n",
    "Disney World tickets are non-refundable. However, some tickets can be modified or upgraded.\n",
    "I am living outside the US and I am not able to purchase tickets online, what should I do?\n",
    "Contact Disney World Guest Services for assistance with international ticket purchases.\n",
    "Post-Visit Queries\n",
    "Till when can I access my photos from the PhotoPass service?\n",
    "Photos from the PhotoPass service are available online for 45 days after the date they were taken.\n",
    "Can I purchase a memory maker package after my visit?\n",
    "Yes, you can purchase a Memory Maker package before, during, or after your visit, but it is recommended to purchase in advance for the best value.\n",
    "Why doesn't Disney World provide lifetime passes?\n",
    "Due to the dynamic nature of the parks and pricing models, lifetime passes are not feasible.\n",
    "Where can I get assistance if I have questions after my visit?\n",
    "You can contact Disney World Guest Services via their website or call (407) 939-5277.\n",
    "If I visit Disney World late, can I still experience the main attractions?\n",
    "Yes, but it is advisable to plan your visit and use Genie+ to maximize your experience.\n",
    "I am living outside the US and I am not able to access certain services online, what should I do?\n",
    "Contact Disney World Guest Services for help with international access issues.\n",
    "Special Programs and Assistance Queries\n",
    "What is the criteria to get a FastPass?\n",
    "FastPass is now replaced by Disney Genie+ service. Check the official website for details on how to use this service.\n",
    "I am joining late. How can I catch up on missed attractions?\n",
    "Plan your visit using the Disney Genie+ service and prioritize the attractions you missed.\n",
    "What does the VIP Tour Service include?\n",
    "VIP Tour Service provides a customized tour experience with priority access to attractions, dining reservations, and personalized itineraries.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e68aeb38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-29 08:41:14.398869: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88755420",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0b51b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts([faqs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "384752d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "293"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "039f7c79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'disney': 2,\n",
       " 'world': 3,\n",
       " 'i': 4,\n",
       " 'can': 5,\n",
       " 'and': 6,\n",
       " 'for': 7,\n",
       " 'to': 8,\n",
       " 'a': 9,\n",
       " 'what': 10,\n",
       " 'you': 11,\n",
       " 'is': 12,\n",
       " 'visit': 13,\n",
       " 'attractions': 14,\n",
       " 'in': 15,\n",
       " 'tickets': 16,\n",
       " 'day': 17,\n",
       " 'yes': 18,\n",
       " 'service': 19,\n",
       " 'or': 20,\n",
       " 'on': 21,\n",
       " 'ticket': 22,\n",
       " 'at': 23,\n",
       " 'with': 24,\n",
       " 'are': 25,\n",
       " 'if': 26,\n",
       " 'website': 27,\n",
       " 'services': 28,\n",
       " 'of': 29,\n",
       " 'your': 30,\n",
       " 'purchase': 31,\n",
       " 'days': 32,\n",
       " 'use': 33,\n",
       " 'do': 34,\n",
       " 'after': 35,\n",
       " 'am': 36,\n",
       " 'experience': 37,\n",
       " 'check': 38,\n",
       " 'get': 39,\n",
       " 'genie': 40,\n",
       " 'where': 41,\n",
       " 'parades': 42,\n",
       " 'fireworks': 43,\n",
       " 'official': 44,\n",
       " 'how': 45,\n",
       " 'have': 46,\n",
       " 'enter': 47,\n",
       " 'contact': 48,\n",
       " 'guest': 49,\n",
       " 'access': 50,\n",
       " 'about': 51,\n",
       " 'date': 52,\n",
       " 'from': 53,\n",
       " \"disney's\": 54,\n",
       " 'last': 55,\n",
       " 'but': 56,\n",
       " 'be': 57,\n",
       " 'park': 58,\n",
       " 'issues': 59,\n",
       " 'programs': 60,\n",
       " 'queries': 61,\n",
       " 'we': 62,\n",
       " 'should': 63,\n",
       " 'advance': 64,\n",
       " 'multi': 65,\n",
       " 'it': 66,\n",
       " 'when': 67,\n",
       " 'not': 68,\n",
       " 'online': 69,\n",
       " 'assistance': 70,\n",
       " 'my': 71,\n",
       " 'tour': 72,\n",
       " 'single': 73,\n",
       " 'start': 74,\n",
       " 'typical': 75,\n",
       " 'main': 76,\n",
       " 'kingdom': 77,\n",
       " 'hollywood': 78,\n",
       " 'studios': 79,\n",
       " 'parks': 80,\n",
       " 'dining': 81,\n",
       " 'star': 82,\n",
       " 'wars': 83,\n",
       " \"galaxy's\": 84,\n",
       " 'edge': 85,\n",
       " 'popular': 86,\n",
       " 'reservations': 87,\n",
       " 'find': 88,\n",
       " 'app': 89,\n",
       " 'up': 90,\n",
       " 'long': 91,\n",
       " 'minutes': 92,\n",
       " '15': 93,\n",
       " 'languages': 94,\n",
       " 'by': 95,\n",
       " 'staff': 96,\n",
       " 'multiple': 97,\n",
       " 'will': 98,\n",
       " 'hours': 99,\n",
       " 'through': 100,\n",
       " 'mobility': 101,\n",
       " 'any': 102,\n",
       " 'during': 103,\n",
       " 're': 104,\n",
       " 'same': 105,\n",
       " 'as': 106,\n",
       " 'valid': 107,\n",
       " 'educational': 108,\n",
       " 'call': 109,\n",
       " '407': 110,\n",
       " '939': 111,\n",
       " '5277': 112,\n",
       " 'their': 113,\n",
       " 'using': 114,\n",
       " 'details': 115,\n",
       " 'purchasing': 116,\n",
       " 'living': 117,\n",
       " 'outside': 118,\n",
       " 'us': 119,\n",
       " 'able': 120,\n",
       " 'international': 121,\n",
       " 'photos': 122,\n",
       " 'photopass': 123,\n",
       " 'memory': 124,\n",
       " 'maker': 125,\n",
       " 'package': 126,\n",
       " 'lifetime': 127,\n",
       " 'passes': 128,\n",
       " 'late': 129,\n",
       " 'plan': 130,\n",
       " 'fastpass': 131,\n",
       " 'missed': 132,\n",
       " 'vip': 133,\n",
       " 'entrance': 134,\n",
       " 'fee': 135,\n",
       " '2023': 136,\n",
       " 'vary': 137,\n",
       " 'price': 138,\n",
       " 'depending': 139,\n",
       " 'type': 140,\n",
       " '109': 141,\n",
       " 'adults': 142,\n",
       " 'total': 143,\n",
       " 'duration': 144,\n",
       " 'range': 145,\n",
       " 'week': 146,\n",
       " '4': 147,\n",
       " '7': 148,\n",
       " 'being': 149,\n",
       " 'ideal': 150,\n",
       " 'most': 151,\n",
       " 'features': 152,\n",
       " 'following': 153,\n",
       " 'key': 154,\n",
       " 'magic': 155,\n",
       " 'epcot': 156,\n",
       " 'animal': 157,\n",
       " 'water': 158,\n",
       " 'blizzard': 159,\n",
       " 'beach': 160,\n",
       " 'typhoon': 161,\n",
       " 'lagoon': 162,\n",
       " 'springs': 163,\n",
       " 'shopping': 164,\n",
       " 'numerous': 165,\n",
       " 'resorts': 166,\n",
       " 'hotels': 167,\n",
       " 'detailed': 168,\n",
       " 'list': 169,\n",
       " 'here': 170,\n",
       " 'https': 171,\n",
       " 'disneyworld': 172,\n",
       " 'go': 173,\n",
       " 'com': 174,\n",
       " 'part': 175,\n",
       " 'located': 176,\n",
       " 'miss': 177,\n",
       " 'reservation': 178,\n",
       " 'ride': 179,\n",
       " 'another': 180,\n",
       " 'chance': 181,\n",
       " 'book': 182,\n",
       " 'rides': 183,\n",
       " 'throughout': 184,\n",
       " 'schedule': 185,\n",
       " 'schedules': 186,\n",
       " 'typically': 187,\n",
       " '30': 188,\n",
       " 'shows': 189,\n",
       " 'around': 190,\n",
       " '20': 191,\n",
       " 'spoken': 192,\n",
       " 'speak': 193,\n",
       " 'english': 194,\n",
       " 'guides': 195,\n",
       " 'informed': 196,\n",
       " 'changes': 197,\n",
       " 'updates': 198,\n",
       " 'equipped': 199,\n",
       " 'facilities': 200,\n",
       " 'assist': 201,\n",
       " 'guests': 202,\n",
       " 'middle': 203,\n",
       " 'allows': 204,\n",
       " 'time': 205,\n",
       " \"park's\": 206,\n",
       " 'operating': 207,\n",
       " 'leave': 208,\n",
       " 'hand': 209,\n",
       " 'stamp': 210,\n",
       " 'there': 211,\n",
       " 'offers': 212,\n",
       " 'several': 213,\n",
       " 'tours': 214,\n",
       " 'all': 215,\n",
       " 'age': 216,\n",
       " 'groups': 217,\n",
       " 'more': 218,\n",
       " 'information': 219,\n",
       " 'payment': 220,\n",
       " 'buy': 221,\n",
       " 'them': 222,\n",
       " 'youtube': 223,\n",
       " 'purchased': 224,\n",
       " 'authorized': 225,\n",
       " 'sellers': 226,\n",
       " 'pay': 227,\n",
       " 'which': 228,\n",
       " 'often': 229,\n",
       " 'come': 230,\n",
       " 'discounts': 231,\n",
       " 'validity': 232,\n",
       " 'january': 233,\n",
       " 'remaining': 234,\n",
       " 'specific': 235,\n",
       " 'period': 236,\n",
       " 'usually': 237,\n",
       " 'within': 238,\n",
       " '14': 239,\n",
       " 'first': 240,\n",
       " \"don't\": 241,\n",
       " 'enjoy': 242,\n",
       " 'refund': 243,\n",
       " 'policy': 244,\n",
       " 'non': 245,\n",
       " 'refundable': 246,\n",
       " 'however': 247,\n",
       " 'some': 248,\n",
       " 'modified': 249,\n",
       " 'upgraded': 250,\n",
       " 'purchases': 251,\n",
       " 'post': 252,\n",
       " 'till': 253,\n",
       " 'available': 254,\n",
       " '45': 255,\n",
       " 'they': 256,\n",
       " 'were': 257,\n",
       " 'taken': 258,\n",
       " 'before': 259,\n",
       " 'recommended': 260,\n",
       " 'best': 261,\n",
       " 'value': 262,\n",
       " 'why': 263,\n",
       " \"doesn't\": 264,\n",
       " 'provide': 265,\n",
       " 'due': 266,\n",
       " 'dynamic': 267,\n",
       " 'nature': 268,\n",
       " 'pricing': 269,\n",
       " 'models': 270,\n",
       " 'feasible': 271,\n",
       " 'questions': 272,\n",
       " 'via': 273,\n",
       " 'still': 274,\n",
       " 'advisable': 275,\n",
       " 'maximize': 276,\n",
       " 'certain': 277,\n",
       " 'help': 278,\n",
       " 'special': 279,\n",
       " 'criteria': 280,\n",
       " 'now': 281,\n",
       " 'replaced': 282,\n",
       " 'this': 283,\n",
       " 'joining': 284,\n",
       " 'catch': 285,\n",
       " 'prioritize': 286,\n",
       " 'does': 287,\n",
       " 'include': 288,\n",
       " 'provides': 289,\n",
       " 'customized': 290,\n",
       " 'priority': 291,\n",
       " 'personalized': 292,\n",
       " 'itineraries': 293}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad34b6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_sequences = []\n",
    "# for sentence in faqs.split('\\n'):\n",
    "#   tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0]\n",
    "\n",
    "#   for i in range(1,len(tokenized_sentence)):\n",
    "#     input_sequences.append(tokenized_sentence[:i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e96e4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = []\n",
    "for i in faqs.split('\\n'):\n",
    "    tokenized_sentence = tokenizer.texts_to_sequences([i])[0]\n",
    "    \n",
    "    \n",
    "    for j in range(1,len(tokenized_sentence)):\n",
    "        input_sequences.append(tokenized_sentence[:j+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30739fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[51, 2],\n",
       " [51, 2, 3],\n",
       " [10, 12],\n",
       " [10, 12, 1],\n",
       " [10, 12, 1, 134],\n",
       " [10, 12, 1, 134, 135],\n",
       " [10, 12, 1, 134, 135, 7],\n",
       " [10, 12, 1, 134, 135, 7, 2],\n",
       " [10, 12, 1, 134, 135, 7, 2, 3],\n",
       " [10, 12, 1, 134, 135, 7, 2, 3, 15],\n",
       " [10, 12, 1, 134, 135, 7, 2, 3, 15, 136],\n",
       " [2, 3],\n",
       " [2, 3, 16],\n",
       " [2, 3, 16, 137],\n",
       " [2, 3, 16, 137, 15],\n",
       " [2, 3, 16, 137, 15, 138],\n",
       " [2, 3, 16, 137, 15, 138, 139],\n",
       " [2, 3, 16, 137, 15, 138, 139, 21],\n",
       " [2, 3, 16, 137, 15, 138, 139, 21, 1],\n",
       " [2, 3, 16, 137, 15, 138, 139, 21, 1, 52],\n",
       " [2, 3, 16, 137, 15, 138, 139, 21, 1, 52, 6],\n",
       " [2, 3, 16, 137, 15, 138, 139, 21, 1, 52, 6, 1],\n",
       " [2, 3, 16, 137, 15, 138, 139, 21, 1, 52, 6, 1, 140],\n",
       " [2, 3, 16, 137, 15, 138, 139, 21, 1, 52, 6, 1, 140, 29],\n",
       " [2, 3, 16, 137, 15, 138, 139, 21, 1, 52, 6, 1, 140, 29, 22],\n",
       " [2, 3, 16, 137, 15, 138, 139, 21, 1, 52, 6, 1, 140, 29, 22, 73],\n",
       " [2, 3, 16, 137, 15, 138, 139, 21, 1, 52, 6, 1, 140, 29, 22, 73, 17],\n",
       " [2, 3, 16, 137, 15, 138, 139, 21, 1, 52, 6, 1, 140, 29, 22, 73, 17, 16],\n",
       " [2, 3, 16, 137, 15, 138, 139, 21, 1, 52, 6, 1, 140, 29, 22, 73, 17, 16, 74],\n",
       " [2,\n",
       "  3,\n",
       "  16,\n",
       "  137,\n",
       "  15,\n",
       "  138,\n",
       "  139,\n",
       "  21,\n",
       "  1,\n",
       "  52,\n",
       "  6,\n",
       "  1,\n",
       "  140,\n",
       "  29,\n",
       "  22,\n",
       "  73,\n",
       "  17,\n",
       "  16,\n",
       "  74,\n",
       "  23],\n",
       " [2,\n",
       "  3,\n",
       "  16,\n",
       "  137,\n",
       "  15,\n",
       "  138,\n",
       "  139,\n",
       "  21,\n",
       "  1,\n",
       "  52,\n",
       "  6,\n",
       "  1,\n",
       "  140,\n",
       "  29,\n",
       "  22,\n",
       "  73,\n",
       "  17,\n",
       "  16,\n",
       "  74,\n",
       "  23,\n",
       "  141],\n",
       " [2,\n",
       "  3,\n",
       "  16,\n",
       "  137,\n",
       "  15,\n",
       "  138,\n",
       "  139,\n",
       "  21,\n",
       "  1,\n",
       "  52,\n",
       "  6,\n",
       "  1,\n",
       "  140,\n",
       "  29,\n",
       "  22,\n",
       "  73,\n",
       "  17,\n",
       "  16,\n",
       "  74,\n",
       "  23,\n",
       "  141,\n",
       "  7],\n",
       " [2,\n",
       "  3,\n",
       "  16,\n",
       "  137,\n",
       "  15,\n",
       "  138,\n",
       "  139,\n",
       "  21,\n",
       "  1,\n",
       "  52,\n",
       "  6,\n",
       "  1,\n",
       "  140,\n",
       "  29,\n",
       "  22,\n",
       "  73,\n",
       "  17,\n",
       "  16,\n",
       "  74,\n",
       "  23,\n",
       "  141,\n",
       "  7,\n",
       "  142],\n",
       " [10, 12],\n",
       " [10, 12, 1],\n",
       " [10, 12, 1, 143],\n",
       " [10, 12, 1, 143, 144],\n",
       " [10, 12, 1, 143, 144, 7],\n",
       " [10, 12, 1, 143, 144, 7, 9],\n",
       " [10, 12, 1, 143, 144, 7, 9, 75],\n",
       " [10, 12, 1, 143, 144, 7, 9, 75, 2],\n",
       " [10, 12, 1, 143, 144, 7, 9, 75, 2, 3],\n",
       " [10, 12, 1, 143, 144, 7, 9, 75, 2, 3, 13],\n",
       " [9, 75],\n",
       " [9, 75, 13],\n",
       " [9, 75, 13, 8],\n",
       " [9, 75, 13, 8, 2],\n",
       " [9, 75, 13, 8, 2, 3],\n",
       " [9, 75, 13, 8, 2, 3, 5],\n",
       " [9, 75, 13, 8, 2, 3, 5, 145],\n",
       " [9, 75, 13, 8, 2, 3, 5, 145, 53],\n",
       " [9, 75, 13, 8, 2, 3, 5, 145, 53, 9],\n",
       " [9, 75, 13, 8, 2, 3, 5, 145, 53, 9, 73],\n",
       " [9, 75, 13, 8, 2, 3, 5, 145, 53, 9, 73, 17],\n",
       " [9, 75, 13, 8, 2, 3, 5, 145, 53, 9, 73, 17, 8],\n",
       " [9, 75, 13, 8, 2, 3, 5, 145, 53, 9, 73, 17, 8, 9],\n",
       " [9, 75, 13, 8, 2, 3, 5, 145, 53, 9, 73, 17, 8, 9, 146],\n",
       " [9, 75, 13, 8, 2, 3, 5, 145, 53, 9, 73, 17, 8, 9, 146, 24],\n",
       " [9, 75, 13, 8, 2, 3, 5, 145, 53, 9, 73, 17, 8, 9, 146, 24, 147],\n",
       " [9, 75, 13, 8, 2, 3, 5, 145, 53, 9, 73, 17, 8, 9, 146, 24, 147, 8],\n",
       " [9, 75, 13, 8, 2, 3, 5, 145, 53, 9, 73, 17, 8, 9, 146, 24, 147, 8, 148],\n",
       " [9, 75, 13, 8, 2, 3, 5, 145, 53, 9, 73, 17, 8, 9, 146, 24, 147, 8, 148, 32],\n",
       " [9,\n",
       "  75,\n",
       "  13,\n",
       "  8,\n",
       "  2,\n",
       "  3,\n",
       "  5,\n",
       "  145,\n",
       "  53,\n",
       "  9,\n",
       "  73,\n",
       "  17,\n",
       "  8,\n",
       "  9,\n",
       "  146,\n",
       "  24,\n",
       "  147,\n",
       "  8,\n",
       "  148,\n",
       "  32,\n",
       "  149],\n",
       " [9,\n",
       "  75,\n",
       "  13,\n",
       "  8,\n",
       "  2,\n",
       "  3,\n",
       "  5,\n",
       "  145,\n",
       "  53,\n",
       "  9,\n",
       "  73,\n",
       "  17,\n",
       "  8,\n",
       "  9,\n",
       "  146,\n",
       "  24,\n",
       "  147,\n",
       "  8,\n",
       "  148,\n",
       "  32,\n",
       "  149,\n",
       "  150],\n",
       " [9,\n",
       "  75,\n",
       "  13,\n",
       "  8,\n",
       "  2,\n",
       "  3,\n",
       "  5,\n",
       "  145,\n",
       "  53,\n",
       "  9,\n",
       "  73,\n",
       "  17,\n",
       "  8,\n",
       "  9,\n",
       "  146,\n",
       "  24,\n",
       "  147,\n",
       "  8,\n",
       "  148,\n",
       "  32,\n",
       "  149,\n",
       "  150,\n",
       "  8],\n",
       " [9,\n",
       "  75,\n",
       "  13,\n",
       "  8,\n",
       "  2,\n",
       "  3,\n",
       "  5,\n",
       "  145,\n",
       "  53,\n",
       "  9,\n",
       "  73,\n",
       "  17,\n",
       "  8,\n",
       "  9,\n",
       "  146,\n",
       "  24,\n",
       "  147,\n",
       "  8,\n",
       "  148,\n",
       "  32,\n",
       "  149,\n",
       "  150,\n",
       "  8,\n",
       "  37],\n",
       " [9,\n",
       "  75,\n",
       "  13,\n",
       "  8,\n",
       "  2,\n",
       "  3,\n",
       "  5,\n",
       "  145,\n",
       "  53,\n",
       "  9,\n",
       "  73,\n",
       "  17,\n",
       "  8,\n",
       "  9,\n",
       "  146,\n",
       "  24,\n",
       "  147,\n",
       "  8,\n",
       "  148,\n",
       "  32,\n",
       "  149,\n",
       "  150,\n",
       "  8,\n",
       "  37,\n",
       "  151],\n",
       " [9,\n",
       "  75,\n",
       "  13,\n",
       "  8,\n",
       "  2,\n",
       "  3,\n",
       "  5,\n",
       "  145,\n",
       "  53,\n",
       "  9,\n",
       "  73,\n",
       "  17,\n",
       "  8,\n",
       "  9,\n",
       "  146,\n",
       "  24,\n",
       "  147,\n",
       "  8,\n",
       "  148,\n",
       "  32,\n",
       "  149,\n",
       "  150,\n",
       "  8,\n",
       "  37,\n",
       "  151,\n",
       "  14],\n",
       " [10, 25],\n",
       " [10, 25, 1],\n",
       " [10, 25, 1, 76],\n",
       " [10, 25, 1, 76, 14],\n",
       " [10, 25, 1, 76, 14, 23],\n",
       " [10, 25, 1, 76, 14, 23, 2],\n",
       " [10, 25, 1, 76, 14, 23, 2, 3],\n",
       " [2, 3],\n",
       " [2, 3, 152],\n",
       " [2, 3, 152, 1],\n",
       " [2, 3, 152, 1, 153],\n",
       " [2, 3, 152, 1, 153, 154],\n",
       " [2, 3, 152, 1, 153, 154, 14],\n",
       " [155, 77],\n",
       " [54, 78],\n",
       " [54, 78, 79],\n",
       " [54, 157],\n",
       " [54, 157, 77],\n",
       " [158, 80],\n",
       " [158, 80, 159],\n",
       " [158, 80, 159, 160],\n",
       " [158, 80, 159, 160, 6],\n",
       " [158, 80, 159, 160, 6, 161],\n",
       " [158, 80, 159, 160, 6, 161, 162],\n",
       " [2, 163],\n",
       " [2, 163, 7],\n",
       " [2, 163, 7, 164],\n",
       " [2, 163, 7, 164, 6],\n",
       " [2, 163, 7, 164, 6, 81],\n",
       " [165, 166],\n",
       " [165, 166, 6],\n",
       " [165, 166, 6, 167],\n",
       " [11, 5],\n",
       " [11, 5, 38],\n",
       " [11, 5, 38, 1],\n",
       " [11, 5, 38, 1, 168],\n",
       " [11, 5, 38, 1, 168, 14],\n",
       " [11, 5, 38, 1, 168, 14, 169],\n",
       " [11, 5, 38, 1, 168, 14, 169, 170],\n",
       " [11, 5, 38, 1, 168, 14, 169, 170, 171],\n",
       " [11, 5, 38, 1, 168, 14, 169, 170, 171, 172],\n",
       " [11, 5, 38, 1, 168, 14, 169, 170, 171, 172, 2],\n",
       " [11, 5, 38, 1, 168, 14, 169, 170, 171, 172, 2, 173],\n",
       " [11, 5, 38, 1, 168, 14, 169, 170, 171, 172, 2, 173, 174],\n",
       " [12, 1],\n",
       " [12, 1, 82],\n",
       " [12, 1, 82, 83],\n",
       " [12, 1, 82, 83, 84],\n",
       " [12, 1, 82, 83, 84, 85],\n",
       " [12, 1, 82, 83, 84, 85, 175],\n",
       " [12, 1, 82, 83, 84, 85, 175, 29],\n",
       " [12, 1, 82, 83, 84, 85, 175, 29, 2],\n",
       " [12, 1, 82, 83, 84, 85, 175, 29, 2, 3],\n",
       " [18, 82],\n",
       " [18, 82, 83],\n",
       " [18, 82, 83, 84],\n",
       " [18, 82, 83, 84, 85],\n",
       " [18, 82, 83, 84, 85, 12],\n",
       " [18, 82, 83, 84, 85, 12, 176],\n",
       " [18, 82, 83, 84, 85, 12, 176, 15],\n",
       " [18, 82, 83, 84, 85, 12, 176, 15, 54],\n",
       " [18, 82, 83, 84, 85, 12, 176, 15, 54, 78],\n",
       " [18, 82, 83, 84, 85, 12, 176, 15, 54, 78, 79],\n",
       " [10, 26],\n",
       " [10, 26, 4],\n",
       " [10, 26, 4, 177],\n",
       " [10, 26, 4, 177, 9],\n",
       " [10, 26, 4, 177, 9, 178],\n",
       " [10, 26, 4, 177, 9, 178, 7],\n",
       " [10, 26, 4, 177, 9, 178, 7, 9],\n",
       " [10, 26, 4, 177, 9, 178, 7, 9, 86],\n",
       " [10, 26, 4, 177, 9, 178, 7, 9, 86, 179],\n",
       " [10, 26, 4, 177, 9, 178, 7, 9, 86, 179, 5],\n",
       " [10, 26, 4, 177, 9, 178, 7, 9, 86, 179, 5, 4],\n",
       " [10, 26, 4, 177, 9, 178, 7, 9, 86, 179, 5, 4, 39],\n",
       " [10, 26, 4, 177, 9, 178, 7, 9, 86, 179, 5, 4, 39, 180],\n",
       " [10, 26, 4, 177, 9, 178, 7, 9, 86, 179, 5, 4, 39, 180, 181],\n",
       " [18, 11],\n",
       " [18, 11, 5],\n",
       " [18, 11, 5, 33],\n",
       " [18, 11, 5, 33, 1],\n",
       " [18, 11, 5, 33, 1, 2],\n",
       " [18, 11, 5, 33, 1, 2, 40],\n",
       " [18, 11, 5, 33, 1, 2, 40, 19],\n",
       " [18, 11, 5, 33, 1, 2, 40, 19, 8],\n",
       " [18, 11, 5, 33, 1, 2, 40, 19, 8, 182],\n",
       " [18, 11, 5, 33, 1, 2, 40, 19, 8, 182, 87],\n",
       " [18, 11, 5, 33, 1, 2, 40, 19, 8, 182, 87, 7],\n",
       " [18, 11, 5, 33, 1, 2, 40, 19, 8, 182, 87, 7, 86],\n",
       " [18, 11, 5, 33, 1, 2, 40, 19, 8, 182, 87, 7, 86, 183],\n",
       " [18, 11, 5, 33, 1, 2, 40, 19, 8, 182, 87, 7, 86, 183, 6],\n",
       " [18, 11, 5, 33, 1, 2, 40, 19, 8, 182, 87, 7, 86, 183, 6, 14],\n",
       " [18, 11, 5, 33, 1, 2, 40, 19, 8, 182, 87, 7, 86, 183, 6, 14, 184],\n",
       " [18, 11, 5, 33, 1, 2, 40, 19, 8, 182, 87, 7, 86, 183, 6, 14, 184, 1],\n",
       " [18, 11, 5, 33, 1, 2, 40, 19, 8, 182, 87, 7, 86, 183, 6, 14, 184, 1, 17],\n",
       " [41, 5],\n",
       " [41, 5, 4],\n",
       " [41, 5, 4, 88],\n",
       " [41, 5, 4, 88, 1],\n",
       " [41, 5, 4, 88, 1, 185],\n",
       " [41, 5, 4, 88, 1, 185, 7],\n",
       " [41, 5, 4, 88, 1, 185, 7, 42],\n",
       " [41, 5, 4, 88, 1, 185, 7, 42, 6],\n",
       " [41, 5, 4, 88, 1, 185, 7, 42, 6, 43],\n",
       " [38, 1],\n",
       " [38, 1, 44],\n",
       " [38, 1, 44, 2],\n",
       " [38, 1, 44, 2, 3],\n",
       " [38, 1, 44, 2, 3, 89],\n",
       " [38, 1, 44, 2, 3, 89, 20],\n",
       " [38, 1, 44, 2, 3, 89, 20, 27],\n",
       " [38, 1, 44, 2, 3, 89, 20, 27, 7],\n",
       " [38, 1, 44, 2, 3, 89, 20, 27, 7, 90],\n",
       " [38, 1, 44, 2, 3, 89, 20, 27, 7, 90, 8],\n",
       " [38, 1, 44, 2, 3, 89, 20, 27, 7, 90, 8, 52],\n",
       " [38, 1, 44, 2, 3, 89, 20, 27, 7, 90, 8, 52, 186],\n",
       " [38, 1, 44, 2, 3, 89, 20, 27, 7, 90, 8, 52, 186, 7],\n",
       " [38, 1, 44, 2, 3, 89, 20, 27, 7, 90, 8, 52, 186, 7, 42],\n",
       " [38, 1, 44, 2, 3, 89, 20, 27, 7, 90, 8, 52, 186, 7, 42, 6],\n",
       " [38, 1, 44, 2, 3, 89, 20, 27, 7, 90, 8, 52, 186, 7, 42, 6, 43],\n",
       " [45, 91],\n",
       " [45, 91, 34],\n",
       " [45, 91, 34, 42],\n",
       " [45, 91, 34, 42, 6],\n",
       " [45, 91, 34, 42, 6, 43],\n",
       " [45, 91, 34, 42, 6, 43, 55],\n",
       " [42, 187],\n",
       " [42, 187, 55],\n",
       " [42, 187, 55, 51],\n",
       " [42, 187, 55, 51, 188],\n",
       " [42, 187, 55, 51, 188, 92],\n",
       " [42, 187, 55, 51, 188, 92, 6],\n",
       " [42, 187, 55, 51, 188, 92, 6, 43],\n",
       " [42, 187, 55, 51, 188, 92, 6, 43, 189],\n",
       " [42, 187, 55, 51, 188, 92, 6, 43, 189, 55],\n",
       " [42, 187, 55, 51, 188, 92, 6, 43, 189, 55, 190],\n",
       " [42, 187, 55, 51, 188, 92, 6, 43, 189, 55, 190, 93],\n",
       " [42, 187, 55, 51, 188, 92, 6, 43, 189, 55, 190, 93, 8],\n",
       " [42, 187, 55, 51, 188, 92, 6, 43, 189, 55, 190, 93, 8, 191],\n",
       " [42, 187, 55, 51, 188, 92, 6, 43, 189, 55, 190, 93, 8, 191, 92],\n",
       " [10, 94],\n",
       " [10, 94, 25],\n",
       " [10, 94, 25, 192],\n",
       " [10, 94, 25, 192, 95],\n",
       " [10, 94, 25, 192, 95, 1],\n",
       " [10, 94, 25, 192, 95, 1, 96],\n",
       " [10, 94, 25, 192, 95, 1, 96, 23],\n",
       " [10, 94, 25, 192, 95, 1, 96, 23, 2],\n",
       " [10, 94, 25, 192, 95, 1, 96, 23, 2, 3],\n",
       " [96, 23],\n",
       " [96, 23, 2],\n",
       " [96, 23, 2, 3],\n",
       " [96, 23, 2, 3, 193],\n",
       " [96, 23, 2, 3, 193, 194],\n",
       " [96, 23, 2, 3, 193, 194, 56],\n",
       " [96, 23, 2, 3, 193, 194, 56, 11],\n",
       " [96, 23, 2, 3, 193, 194, 56, 11, 5],\n",
       " [96, 23, 2, 3, 193, 194, 56, 11, 5, 88],\n",
       " [96, 23, 2, 3, 193, 194, 56, 11, 5, 88, 195],\n",
       " [96, 23, 2, 3, 193, 194, 56, 11, 5, 88, 195, 6],\n",
       " [96, 23, 2, 3, 193, 194, 56, 11, 5, 88, 195, 6, 28],\n",
       " [96, 23, 2, 3, 193, 194, 56, 11, 5, 88, 195, 6, 28, 15],\n",
       " [96, 23, 2, 3, 193, 194, 56, 11, 5, 88, 195, 6, 28, 15, 97],\n",
       " [96, 23, 2, 3, 193, 194, 56, 11, 5, 88, 195, 6, 28, 15, 97, 94],\n",
       " [45, 98],\n",
       " [45, 98, 4],\n",
       " [45, 98, 4, 57],\n",
       " [45, 98, 4, 57, 196],\n",
       " [45, 98, 4, 57, 196, 51],\n",
       " [45, 98, 4, 57, 196, 51, 197],\n",
       " [45, 98, 4, 57, 196, 51, 197, 15],\n",
       " [45, 98, 4, 57, 196, 51, 197, 15, 58],\n",
       " [45, 98, 4, 57, 196, 51, 197, 15, 58, 99],\n",
       " [45, 98, 4, 57, 196, 51, 197, 15, 58, 99, 20],\n",
       " [45, 98, 4, 57, 196, 51, 197, 15, 58, 99, 20, 14],\n",
       " [11, 98],\n",
       " [11, 98, 39],\n",
       " [11, 98, 39, 198],\n",
       " [11, 98, 39, 198, 100],\n",
       " [11, 98, 39, 198, 100, 1],\n",
       " [11, 98, 39, 198, 100, 1, 44],\n",
       " [11, 98, 39, 198, 100, 1, 44, 2],\n",
       " [11, 98, 39, 198, 100, 1, 44, 2, 3],\n",
       " [11, 98, 39, 198, 100, 1, 44, 2, 3, 89],\n",
       " [11, 98, 39, 198, 100, 1, 44, 2, 3, 89, 6],\n",
       " [11, 98, 39, 198, 100, 1, 44, 2, 3, 89, 6, 27],\n",
       " [5, 4],\n",
       " [5, 4, 13],\n",
       " [5, 4, 13, 2],\n",
       " [5, 4, 13, 2, 3],\n",
       " [5, 4, 13, 2, 3, 26],\n",
       " [5, 4, 13, 2, 3, 26, 4],\n",
       " [5, 4, 13, 2, 3, 26, 4, 46],\n",
       " [5, 4, 13, 2, 3, 26, 4, 46, 101],\n",
       " [5, 4, 13, 2, 3, 26, 4, 46, 101, 59],\n",
       " [18, 2],\n",
       " [18, 2, 3],\n",
       " [18, 2, 3, 12],\n",
       " [18, 2, 3, 12, 199],\n",
       " [18, 2, 3, 12, 199, 24],\n",
       " [18, 2, 3, 12, 199, 24, 200],\n",
       " [18, 2, 3, 12, 199, 24, 200, 6],\n",
       " [18, 2, 3, 12, 199, 24, 200, 6, 28],\n",
       " [18, 2, 3, 12, 199, 24, 200, 6, 28, 8],\n",
       " [18, 2, 3, 12, 199, 24, 200, 6, 28, 8, 201],\n",
       " [18, 2, 3, 12, 199, 24, 200, 6, 28, 8, 201, 202],\n",
       " [18, 2, 3, 12, 199, 24, 200, 6, 28, 8, 201, 202, 24],\n",
       " [18, 2, 3, 12, 199, 24, 200, 6, 28, 8, 201, 202, 24, 101],\n",
       " [18, 2, 3, 12, 199, 24, 200, 6, 28, 8, 201, 202, 24, 101, 59],\n",
       " [5, 4],\n",
       " [5, 4, 47],\n",
       " [5, 4, 47, 2],\n",
       " [5, 4, 47, 2, 3],\n",
       " [5, 4, 47, 2, 3, 15],\n",
       " [5, 4, 47, 2, 3, 15, 1],\n",
       " [5, 4, 47, 2, 3, 15, 1, 203],\n",
       " [5, 4, 47, 2, 3, 15, 1, 203, 29],\n",
       " [5, 4, 47, 2, 3, 15, 1, 203, 29, 1],\n",
       " [5, 4, 47, 2, 3, 15, 1, 203, 29, 1, 17],\n",
       " [18, 30],\n",
       " [18, 30, 22],\n",
       " [18, 30, 22, 204],\n",
       " [18, 30, 22, 204, 11],\n",
       " [18, 30, 22, 204, 11, 8],\n",
       " [18, 30, 22, 204, 11, 8, 47],\n",
       " [18, 30, 22, 204, 11, 8, 47, 2],\n",
       " [18, 30, 22, 204, 11, 8, 47, 2, 3],\n",
       " [18, 30, 22, 204, 11, 8, 47, 2, 3, 23],\n",
       " [18, 30, 22, 204, 11, 8, 47, 2, 3, 23, 102],\n",
       " [18, 30, 22, 204, 11, 8, 47, 2, 3, 23, 102, 205],\n",
       " [18, 30, 22, 204, 11, 8, 47, 2, 3, 23, 102, 205, 103],\n",
       " [18, 30, 22, 204, 11, 8, 47, 2, 3, 23, 102, 205, 103, 1],\n",
       " [18, 30, 22, 204, 11, 8, 47, 2, 3, 23, 102, 205, 103, 1, 206],\n",
       " [18, 30, 22, 204, 11, 8, 47, 2, 3, 23, 102, 205, 103, 1, 206, 207],\n",
       " [18, 30, 22, 204, 11, 8, 47, 2, 3, 23, 102, 205, 103, 1, 206, 207, 99],\n",
       " [26, 4],\n",
       " [26, 4, 208],\n",
       " [26, 4, 208, 1],\n",
       " [26, 4, 208, 1, 58],\n",
       " [26, 4, 208, 1, 58, 5],\n",
       " [26, 4, 208, 1, 58, 5, 4],\n",
       " [26, 4, 208, 1, 58, 5, 4, 104],\n",
       " [26, 4, 208, 1, 58, 5, 4, 104, 47],\n",
       " [26, 4, 208, 1, 58, 5, 4, 104, 47, 21],\n",
       " [26, 4, 208, 1, 58, 5, 4, 104, 47, 21, 1],\n",
       " [26, 4, 208, 1, 58, 5, 4, 104, 47, 21, 1, 105],\n",
       " [26, 4, 208, 1, 58, 5, 4, 104, 47, 21, 1, 105, 17],\n",
       " [18, 11],\n",
       " [18, 11, 5],\n",
       " [18, 11, 5, 104],\n",
       " [18, 11, 5, 104, 47],\n",
       " [18, 11, 5, 104, 47, 1],\n",
       " [18, 11, 5, 104, 47, 1, 58],\n",
       " [18, 11, 5, 104, 47, 1, 58, 21],\n",
       " [18, 11, 5, 104, 47, 1, 58, 21, 1],\n",
       " [18, 11, 5, 104, 47, 1, 58, 21, 1, 105],\n",
       " [18, 11, 5, 104, 47, 1, 58, 21, 1, 105, 17],\n",
       " [18, 11, 5, 104, 47, 1, 58, 21, 1, 105, 17, 106],\n",
       " [18, 11, 5, 104, 47, 1, 58, 21, 1, 105, 17, 106, 91],\n",
       " [18, 11, 5, 104, 47, 1, 58, 21, 1, 105, 17, 106, 91, 106],\n",
       " [18, 11, 5, 104, 47, 1, 58, 21, 1, 105, 17, 106, 91, 106, 11],\n",
       " [18, 11, 5, 104, 47, 1, 58, 21, 1, 105, 17, 106, 91, 106, 11, 46],\n",
       " [18, 11, 5, 104, 47, 1, 58, 21, 1, 105, 17, 106, 91, 106, 11, 46, 9],\n",
       " [18, 11, 5, 104, 47, 1, 58, 21, 1, 105, 17, 106, 91, 106, 11, 46, 9, 107],\n",
       " [18, 11, 5, 104, 47, 1, 58, 21, 1, 105, 17, 106, 91, 106, 11, 46, 9, 107, 22],\n",
       " [18,\n",
       "  11,\n",
       "  5,\n",
       "  104,\n",
       "  47,\n",
       "  1,\n",
       "  58,\n",
       "  21,\n",
       "  1,\n",
       "  105,\n",
       "  17,\n",
       "  106,\n",
       "  91,\n",
       "  106,\n",
       "  11,\n",
       "  46,\n",
       "  9,\n",
       "  107,\n",
       "  22,\n",
       "  6],\n",
       " [18,\n",
       "  11,\n",
       "  5,\n",
       "  104,\n",
       "  47,\n",
       "  1,\n",
       "  58,\n",
       "  21,\n",
       "  1,\n",
       "  105,\n",
       "  17,\n",
       "  106,\n",
       "  91,\n",
       "  106,\n",
       "  11,\n",
       "  46,\n",
       "  9,\n",
       "  107,\n",
       "  22,\n",
       "  6,\n",
       "  209],\n",
       " [18,\n",
       "  11,\n",
       "  5,\n",
       "  104,\n",
       "  47,\n",
       "  1,\n",
       "  58,\n",
       "  21,\n",
       "  1,\n",
       "  105,\n",
       "  17,\n",
       "  106,\n",
       "  91,\n",
       "  106,\n",
       "  11,\n",
       "  46,\n",
       "  9,\n",
       "  107,\n",
       "  22,\n",
       "  6,\n",
       "  209,\n",
       "  210],\n",
       " [25, 211],\n",
       " [25, 211, 102],\n",
       " [25, 211, 102, 108],\n",
       " [25, 211, 102, 108, 60],\n",
       " [25, 211, 102, 108, 60, 23],\n",
       " [25, 211, 102, 108, 60, 23, 2],\n",
       " [25, 211, 102, 108, 60, 23, 2, 3],\n",
       " [18, 2],\n",
       " [18, 2, 3],\n",
       " [18, 2, 3, 212],\n",
       " [18, 2, 3, 212, 213],\n",
       " [18, 2, 3, 212, 213, 108],\n",
       " [18, 2, 3, 212, 213, 108, 60],\n",
       " [18, 2, 3, 212, 213, 108, 60, 6],\n",
       " [18, 2, 3, 212, 213, 108, 60, 6, 214],\n",
       " [18, 2, 3, 212, 213, 108, 60, 6, 214, 7],\n",
       " [18, 2, 3, 212, 213, 108, 60, 6, 214, 7, 215],\n",
       " [18, 2, 3, 212, 213, 108, 60, 6, 214, 7, 215, 216],\n",
       " [18, 2, 3, 212, 213, 108, 60, 6, 214, 7, 215, 216, 217],\n",
       " [41, 5],\n",
       " [41, 5, 4],\n",
       " [41, 5, 4, 48],\n",
       " [41, 5, 4, 48, 2],\n",
       " [41, 5, 4, 48, 2, 3],\n",
       " [41, 5, 4, 48, 2, 3, 7],\n",
       " [41, 5, 4, 48, 2, 3, 7, 218],\n",
       " [41, 5, 4, 48, 2, 3, 7, 218, 219],\n",
       " [11, 5],\n",
       " [11, 5, 109],\n",
       " [11, 5, 109, 2],\n",
       " [11, 5, 109, 2, 3],\n",
       " [11, 5, 109, 2, 3, 49],\n",
       " [11, 5, 109, 2, 3, 49, 28],\n",
       " [11, 5, 109, 2, 3, 49, 28, 23],\n",
       " [11, 5, 109, 2, 3, 49, 28, 23, 110],\n",
       " [11, 5, 109, 2, 3, 49, 28, 23, 110, 111],\n",
       " [11, 5, 109, 2, 3, 49, 28, 23, 110, 111, 112],\n",
       " [11, 5, 109, 2, 3, 49, 28, 23, 110, 111, 112, 20],\n",
       " [11, 5, 109, 2, 3, 49, 28, 23, 110, 111, 112, 20, 13],\n",
       " [11, 5, 109, 2, 3, 49, 28, 23, 110, 111, 112, 20, 13, 113],\n",
       " [11, 5, 109, 2, 3, 49, 28, 23, 110, 111, 112, 20, 13, 113, 27],\n",
       " [220, 6],\n",
       " [220, 6, 22],\n",
       " [220, 6, 22, 61],\n",
       " [41, 34],\n",
       " [41, 34, 62],\n",
       " [41, 34, 62, 31],\n",
       " [41, 34, 62, 31, 16],\n",
       " [41, 34, 62, 31, 16, 7],\n",
       " [41, 34, 62, 31, 16, 7, 2],\n",
       " [41, 34, 62, 31, 16, 7, 2, 3],\n",
       " [41, 34, 62, 31, 16, 7, 2, 3, 5],\n",
       " [41, 34, 62, 31, 16, 7, 2, 3, 5, 62],\n",
       " [41, 34, 62, 31, 16, 7, 2, 3, 5, 62, 221],\n",
       " [41, 34, 62, 31, 16, 7, 2, 3, 5, 62, 221, 222],\n",
       " [41, 34, 62, 31, 16, 7, 2, 3, 5, 62, 221, 222, 21],\n",
       " [41, 34, 62, 31, 16, 7, 2, 3, 5, 62, 221, 222, 21, 223],\n",
       " [41, 34, 62, 31, 16, 7, 2, 3, 5, 62, 221, 222, 21, 223, 20],\n",
       " [41, 34, 62, 31, 16, 7, 2, 3, 5, 62, 221, 222, 21, 223, 20, 30],\n",
       " [41, 34, 62, 31, 16, 7, 2, 3, 5, 62, 221, 222, 21, 223, 20, 30, 27],\n",
       " [16, 63],\n",
       " [16, 63, 57],\n",
       " [16, 63, 57, 224],\n",
       " [16, 63, 57, 224, 100],\n",
       " [16, 63, 57, 224, 100, 1],\n",
       " [16, 63, 57, 224, 100, 1, 44],\n",
       " [16, 63, 57, 224, 100, 1, 44, 2],\n",
       " [16, 63, 57, 224, 100, 1, 44, 2, 3],\n",
       " [16, 63, 57, 224, 100, 1, 44, 2, 3, 27],\n",
       " [16, 63, 57, 224, 100, 1, 44, 2, 3, 27, 20],\n",
       " [16, 63, 57, 224, 100, 1, 44, 2, 3, 27, 20, 225],\n",
       " [16, 63, 57, 224, 100, 1, 44, 2, 3, 27, 20, 225, 226],\n",
       " [5, 62],\n",
       " [5, 62, 227],\n",
       " [5, 62, 227, 7],\n",
       " [5, 62, 227, 7, 97],\n",
       " [5, 62, 227, 7, 97, 32],\n",
       " [5, 62, 227, 7, 97, 32, 15],\n",
       " [5, 62, 227, 7, 97, 32, 15, 64],\n",
       " [18, 11],\n",
       " [18, 11, 5],\n",
       " [18, 11, 5, 31],\n",
       " [18, 11, 5, 31, 65],\n",
       " [18, 11, 5, 31, 65, 17],\n",
       " [18, 11, 5, 31, 65, 17, 16],\n",
       " [18, 11, 5, 31, 65, 17, 16, 15],\n",
       " [18, 11, 5, 31, 65, 17, 16, 15, 64],\n",
       " [18, 11, 5, 31, 65, 17, 16, 15, 64, 228],\n",
       " [18, 11, 5, 31, 65, 17, 16, 15, 64, 228, 229],\n",
       " [18, 11, 5, 31, 65, 17, 16, 15, 64, 228, 229, 230],\n",
       " [18, 11, 5, 31, 65, 17, 16, 15, 64, 228, 229, 230, 24],\n",
       " [18, 11, 5, 31, 65, 17, 16, 15, 64, 228, 229, 230, 24, 231],\n",
       " [10, 12],\n",
       " [10, 12, 1],\n",
       " [10, 12, 1, 232],\n",
       " [10, 12, 1, 232, 29],\n",
       " [10, 12, 1, 232, 29, 9],\n",
       " [10, 12, 1, 232, 29, 9, 65],\n",
       " [10, 12, 1, 232, 29, 9, 65, 17],\n",
       " [10, 12, 1, 232, 29, 9, 65, 17, 22],\n",
       " [10, 12, 1, 232, 29, 9, 65, 17, 22, 26],\n",
       " [10, 12, 1, 232, 29, 9, 65, 17, 22, 26, 4],\n",
       " [10, 12, 1, 232, 29, 9, 65, 17, 22, 26, 4, 74],\n",
       " [10, 12, 1, 232, 29, 9, 65, 17, 22, 26, 4, 74, 114],\n",
       " [10, 12, 1, 232, 29, 9, 65, 17, 22, 26, 4, 74, 114, 66],\n",
       " [10, 12, 1, 232, 29, 9, 65, 17, 22, 26, 4, 74, 114, 66, 21],\n",
       " [10, 12, 1, 232, 29, 9, 65, 17, 22, 26, 4, 74, 114, 66, 21, 233],\n",
       " [10, 12, 1, 232, 29, 9, 65, 17, 22, 26, 4, 74, 114, 66, 21, 233, 93],\n",
       " [10, 12, 1, 232, 29, 9, 65, 17, 22, 26, 4, 74, 114, 66, 21, 233, 93, 67],\n",
       " [10, 12, 1, 232, 29, 9, 65, 17, 22, 26, 4, 74, 114, 66, 21, 233, 93, 67, 34],\n",
       " [10,\n",
       "  12,\n",
       "  1,\n",
       "  232,\n",
       "  29,\n",
       "  9,\n",
       "  65,\n",
       "  17,\n",
       "  22,\n",
       "  26,\n",
       "  4,\n",
       "  74,\n",
       "  114,\n",
       "  66,\n",
       "  21,\n",
       "  233,\n",
       "  93,\n",
       "  67,\n",
       "  34,\n",
       "  4],\n",
       " [10,\n",
       "  12,\n",
       "  1,\n",
       "  232,\n",
       "  29,\n",
       "  9,\n",
       "  65,\n",
       "  17,\n",
       "  22,\n",
       "  26,\n",
       "  4,\n",
       "  74,\n",
       "  114,\n",
       "  66,\n",
       "  21,\n",
       "  233,\n",
       "  93,\n",
       "  67,\n",
       "  34,\n",
       "  4,\n",
       "  46],\n",
       " [10,\n",
       "  12,\n",
       "  1,\n",
       "  232,\n",
       "  29,\n",
       "  9,\n",
       "  65,\n",
       "  17,\n",
       "  22,\n",
       "  26,\n",
       "  4,\n",
       "  74,\n",
       "  114,\n",
       "  66,\n",
       "  21,\n",
       "  233,\n",
       "  93,\n",
       "  67,\n",
       "  34,\n",
       "  4,\n",
       "  46,\n",
       "  8],\n",
       " [10,\n",
       "  12,\n",
       "  1,\n",
       "  232,\n",
       "  29,\n",
       "  9,\n",
       "  65,\n",
       "  17,\n",
       "  22,\n",
       "  26,\n",
       "  4,\n",
       "  74,\n",
       "  114,\n",
       "  66,\n",
       "  21,\n",
       "  233,\n",
       "  93,\n",
       "  67,\n",
       "  34,\n",
       "  4,\n",
       "  46,\n",
       "  8,\n",
       "  33],\n",
       " [10,\n",
       "  12,\n",
       "  1,\n",
       "  232,\n",
       "  29,\n",
       "  9,\n",
       "  65,\n",
       "  17,\n",
       "  22,\n",
       "  26,\n",
       "  4,\n",
       "  74,\n",
       "  114,\n",
       "  66,\n",
       "  21,\n",
       "  233,\n",
       "  93,\n",
       "  67,\n",
       "  34,\n",
       "  4,\n",
       "  46,\n",
       "  8,\n",
       "  33,\n",
       "  1],\n",
       " [10,\n",
       "  12,\n",
       "  1,\n",
       "  232,\n",
       "  29,\n",
       "  9,\n",
       "  65,\n",
       "  17,\n",
       "  22,\n",
       "  26,\n",
       "  4,\n",
       "  74,\n",
       "  114,\n",
       "  66,\n",
       "  21,\n",
       "  233,\n",
       "  93,\n",
       "  67,\n",
       "  34,\n",
       "  4,\n",
       "  46,\n",
       "  8,\n",
       "  33,\n",
       "  1,\n",
       "  234],\n",
       " [10,\n",
       "  12,\n",
       "  1,\n",
       "  232,\n",
       "  29,\n",
       "  9,\n",
       "  65,\n",
       "  17,\n",
       "  22,\n",
       "  26,\n",
       "  4,\n",
       "  74,\n",
       "  114,\n",
       "  66,\n",
       "  21,\n",
       "  233,\n",
       "  93,\n",
       "  67,\n",
       "  34,\n",
       "  4,\n",
       "  46,\n",
       "  8,\n",
       "  33,\n",
       "  1,\n",
       "  234,\n",
       "  32],\n",
       " [65, 17],\n",
       " [65, 17, 16],\n",
       " [65, 17, 16, 25],\n",
       " [65, 17, 16, 25, 107],\n",
       " [65, 17, 16, 25, 107, 7],\n",
       " [65, 17, 16, 25, 107, 7, 9],\n",
       " [65, 17, 16, 25, 107, 7, 9, 235],\n",
       " [65, 17, 16, 25, 107, 7, 9, 235, 236],\n",
       " [65, 17, 16, 25, 107, 7, 9, 235, 236, 237],\n",
       " [65, 17, 16, 25, 107, 7, 9, 235, 236, 237, 238],\n",
       " [65, 17, 16, 25, 107, 7, 9, 235, 236, 237, 238, 239],\n",
       " [65, 17, 16, 25, 107, 7, 9, 235, 236, 237, 238, 239, 32],\n",
       " [65, 17, 16, 25, 107, 7, 9, 235, 236, 237, 238, 239, 32, 29],\n",
       " [65, 17, 16, 25, 107, 7, 9, 235, 236, 237, 238, 239, 32, 29, 1],\n",
       " [65, 17, 16, 25, 107, 7, 9, 235, 236, 237, 238, 239, 32, 29, 1, 240],\n",
       " [65, 17, 16, 25, 107, 7, 9, 235, 236, 237, 238, 239, 32, 29, 1, 240, 33],\n",
       " [65, 17, 16, 25, 107, 7, 9, 235, 236, 237, 238, 239, 32, 29, 1, 240, 33, 38],\n",
       " [65,\n",
       "  17,\n",
       "  16,\n",
       "  25,\n",
       "  107,\n",
       "  7,\n",
       "  9,\n",
       "  235,\n",
       "  236,\n",
       "  237,\n",
       "  238,\n",
       "  239,\n",
       "  32,\n",
       "  29,\n",
       "  1,\n",
       "  240,\n",
       "  33,\n",
       "  38,\n",
       "  1],\n",
       " [65,\n",
       "  17,\n",
       "  16,\n",
       "  25,\n",
       "  107,\n",
       "  7,\n",
       "  9,\n",
       "  235,\n",
       "  236,\n",
       "  237,\n",
       "  238,\n",
       "  239,\n",
       "  32,\n",
       "  29,\n",
       "  1,\n",
       "  240,\n",
       "  33,\n",
       "  38,\n",
       "  1,\n",
       "  115],\n",
       " [65,\n",
       "  17,\n",
       "  16,\n",
       "  25,\n",
       "  107,\n",
       "  7,\n",
       "  9,\n",
       "  235,\n",
       "  236,\n",
       "  237,\n",
       "  238,\n",
       "  239,\n",
       "  32,\n",
       "  29,\n",
       "  1,\n",
       "  240,\n",
       "  33,\n",
       "  38,\n",
       "  1,\n",
       "  115,\n",
       "  67],\n",
       " [65,\n",
       "  17,\n",
       "  16,\n",
       "  25,\n",
       "  107,\n",
       "  7,\n",
       "  9,\n",
       "  235,\n",
       "  236,\n",
       "  237,\n",
       "  238,\n",
       "  239,\n",
       "  32,\n",
       "  29,\n",
       "  1,\n",
       "  240,\n",
       "  33,\n",
       "  38,\n",
       "  1,\n",
       "  115,\n",
       "  67,\n",
       "  116],\n",
       " [10, 26],\n",
       " [10, 26, 4],\n",
       " [10, 26, 4, 241],\n",
       " [10, 26, 4, 241, 242],\n",
       " [10, 26, 4, 241, 242, 2],\n",
       " [10, 26, 4, 241, 242, 2, 3],\n",
       " [10, 26, 4, 241, 242, 2, 3, 35],\n",
       " [10, 26, 4, 241, 242, 2, 3, 35, 116],\n",
       " [10, 26, 4, 241, 242, 2, 3, 35, 116, 9],\n",
       " [10, 26, 4, 241, 242, 2, 3, 35, 116, 9, 22],\n",
       " [10, 26, 4, 241, 242, 2, 3, 35, 116, 9, 22, 10],\n",
       " [10, 26, 4, 241, 242, 2, 3, 35, 116, 9, 22, 10, 12],\n",
       " [10, 26, 4, 241, 242, 2, 3, 35, 116, 9, 22, 10, 12, 1],\n",
       " [10, 26, 4, 241, 242, 2, 3, 35, 116, 9, 22, 10, 12, 1, 243],\n",
       " [10, 26, 4, 241, 242, 2, 3, 35, 116, 9, 22, 10, 12, 1, 243, 244],\n",
       " [2, 3],\n",
       " [2, 3, 16],\n",
       " [2, 3, 16, 25],\n",
       " [2, 3, 16, 25, 245],\n",
       " [2, 3, 16, 25, 245, 246],\n",
       " [2, 3, 16, 25, 245, 246, 247],\n",
       " [2, 3, 16, 25, 245, 246, 247, 248],\n",
       " [2, 3, 16, 25, 245, 246, 247, 248, 16],\n",
       " [2, 3, 16, 25, 245, 246, 247, 248, 16, 5],\n",
       " [2, 3, 16, 25, 245, 246, 247, 248, 16, 5, 57],\n",
       " [2, 3, 16, 25, 245, 246, 247, 248, 16, 5, 57, 249],\n",
       " [2, 3, 16, 25, 245, 246, 247, 248, 16, 5, 57, 249, 20],\n",
       " [2, 3, 16, 25, 245, 246, 247, 248, 16, 5, 57, 249, 20, 250],\n",
       " [4, 36],\n",
       " [4, 36, 117],\n",
       " [4, 36, 117, 118],\n",
       " [4, 36, 117, 118, 1],\n",
       " [4, 36, 117, 118, 1, 119],\n",
       " [4, 36, 117, 118, 1, 119, 6],\n",
       " [4, 36, 117, 118, 1, 119, 6, 4],\n",
       " [4, 36, 117, 118, 1, 119, 6, 4, 36],\n",
       " [4, 36, 117, 118, 1, 119, 6, 4, 36, 68],\n",
       " [4, 36, 117, 118, 1, 119, 6, 4, 36, 68, 120],\n",
       " [4, 36, 117, 118, 1, 119, 6, 4, 36, 68, 120, 8],\n",
       " [4, 36, 117, 118, 1, 119, 6, 4, 36, 68, 120, 8, 31],\n",
       " [4, 36, 117, 118, 1, 119, 6, 4, 36, 68, 120, 8, 31, 16],\n",
       " [4, 36, 117, 118, 1, 119, 6, 4, 36, 68, 120, 8, 31, 16, 69],\n",
       " [4, 36, 117, 118, 1, 119, 6, 4, 36, 68, 120, 8, 31, 16, 69, 10],\n",
       " [4, 36, 117, 118, 1, 119, 6, 4, 36, 68, 120, 8, 31, 16, 69, 10, 63],\n",
       " [4, 36, 117, 118, 1, 119, 6, 4, 36, 68, 120, 8, 31, 16, 69, 10, 63, 4],\n",
       " [4, 36, 117, 118, 1, 119, 6, 4, 36, 68, 120, 8, 31, 16, 69, 10, 63, 4, 34],\n",
       " [48, 2],\n",
       " [48, 2, 3],\n",
       " [48, 2, 3, 49],\n",
       " [48, 2, 3, 49, 28],\n",
       " [48, 2, 3, 49, 28, 7],\n",
       " [48, 2, 3, 49, 28, 7, 70],\n",
       " [48, 2, 3, 49, 28, 7, 70, 24],\n",
       " [48, 2, 3, 49, 28, 7, 70, 24, 121],\n",
       " [48, 2, 3, 49, 28, 7, 70, 24, 121, 22],\n",
       " [48, 2, 3, 49, 28, 7, 70, 24, 121, 22, 251],\n",
       " [252, 13],\n",
       " [252, 13, 61],\n",
       " [253, 67],\n",
       " [253, 67, 5],\n",
       " [253, 67, 5, 4],\n",
       " [253, 67, 5, 4, 50],\n",
       " [253, 67, 5, 4, 50, 71],\n",
       " [253, 67, 5, 4, 50, 71, 122],\n",
       " [253, 67, 5, 4, 50, 71, 122, 53],\n",
       " [253, 67, 5, 4, 50, 71, 122, 53, 1],\n",
       " [253, 67, 5, 4, 50, 71, 122, 53, 1, 123],\n",
       " [253, 67, 5, 4, 50, 71, 122, 53, 1, 123, 19],\n",
       " [122, 53],\n",
       " [122, 53, 1],\n",
       " [122, 53, 1, 123],\n",
       " [122, 53, 1, 123, 19],\n",
       " [122, 53, 1, 123, 19, 25],\n",
       " [122, 53, 1, 123, 19, 25, 254],\n",
       " [122, 53, 1, 123, 19, 25, 254, 69],\n",
       " [122, 53, 1, 123, 19, 25, 254, 69, 7],\n",
       " [122, 53, 1, 123, 19, 25, 254, 69, 7, 255],\n",
       " [122, 53, 1, 123, 19, 25, 254, 69, 7, 255, 32],\n",
       " [122, 53, 1, 123, 19, 25, 254, 69, 7, 255, 32, 35],\n",
       " [122, 53, 1, 123, 19, 25, 254, 69, 7, 255, 32, 35, 1],\n",
       " [122, 53, 1, 123, 19, 25, 254, 69, 7, 255, 32, 35, 1, 52],\n",
       " [122, 53, 1, 123, 19, 25, 254, 69, 7, 255, 32, 35, 1, 52, 256],\n",
       " [122, 53, 1, 123, 19, 25, 254, 69, 7, 255, 32, 35, 1, 52, 256, 257],\n",
       " [122, 53, 1, 123, 19, 25, 254, 69, 7, 255, 32, 35, 1, 52, 256, 257, 258],\n",
       " [5, 4],\n",
       " [5, 4, 31],\n",
       " [5, 4, 31, 9],\n",
       " [5, 4, 31, 9, 124],\n",
       " [5, 4, 31, 9, 124, 125],\n",
       " [5, 4, 31, 9, 124, 125, 126],\n",
       " [5, 4, 31, 9, 124, 125, 126, 35],\n",
       " [5, 4, 31, 9, 124, 125, 126, 35, 71],\n",
       " [5, 4, 31, 9, 124, 125, 126, 35, 71, 13],\n",
       " [18, 11],\n",
       " [18, 11, 5],\n",
       " [18, 11, 5, 31],\n",
       " [18, 11, 5, 31, 9],\n",
       " [18, 11, 5, 31, 9, 124],\n",
       " [18, 11, 5, 31, 9, 124, 125],\n",
       " [18, 11, 5, 31, 9, 124, 125, 126],\n",
       " [18, 11, 5, 31, 9, 124, 125, 126, 259],\n",
       " [18, 11, 5, 31, 9, 124, 125, 126, 259, 103],\n",
       " [18, 11, 5, 31, 9, 124, 125, 126, 259, 103, 20],\n",
       " [18, 11, 5, 31, 9, 124, 125, 126, 259, 103, 20, 35],\n",
       " [18, 11, 5, 31, 9, 124, 125, 126, 259, 103, 20, 35, 30],\n",
       " [18, 11, 5, 31, 9, 124, 125, 126, 259, 103, 20, 35, 30, 13],\n",
       " [18, 11, 5, 31, 9, 124, 125, 126, 259, 103, 20, 35, 30, 13, 56],\n",
       " [18, 11, 5, 31, 9, 124, 125, 126, 259, 103, 20, 35, 30, 13, 56, 66],\n",
       " [18, 11, 5, 31, 9, 124, 125, 126, 259, 103, 20, 35, 30, 13, 56, 66, 12],\n",
       " [18, 11, 5, 31, 9, 124, 125, 126, 259, 103, 20, 35, 30, 13, 56, 66, 12, 260],\n",
       " [18,\n",
       "  11,\n",
       "  5,\n",
       "  31,\n",
       "  9,\n",
       "  124,\n",
       "  125,\n",
       "  126,\n",
       "  259,\n",
       "  103,\n",
       "  20,\n",
       "  35,\n",
       "  30,\n",
       "  13,\n",
       "  56,\n",
       "  66,\n",
       "  12,\n",
       "  260,\n",
       "  8],\n",
       " [18,\n",
       "  11,\n",
       "  5,\n",
       "  31,\n",
       "  9,\n",
       "  124,\n",
       "  125,\n",
       "  126,\n",
       "  259,\n",
       "  103,\n",
       "  20,\n",
       "  35,\n",
       "  30,\n",
       "  13,\n",
       "  56,\n",
       "  66,\n",
       "  12,\n",
       "  260,\n",
       "  8,\n",
       "  31],\n",
       " [18,\n",
       "  11,\n",
       "  5,\n",
       "  31,\n",
       "  9,\n",
       "  124,\n",
       "  125,\n",
       "  126,\n",
       "  259,\n",
       "  103,\n",
       "  20,\n",
       "  35,\n",
       "  30,\n",
       "  13,\n",
       "  56,\n",
       "  66,\n",
       "  12,\n",
       "  260,\n",
       "  8,\n",
       "  31,\n",
       "  15],\n",
       " [18,\n",
       "  11,\n",
       "  5,\n",
       "  31,\n",
       "  9,\n",
       "  124,\n",
       "  125,\n",
       "  126,\n",
       "  259,\n",
       "  103,\n",
       "  20,\n",
       "  35,\n",
       "  30,\n",
       "  13,\n",
       "  56,\n",
       "  66,\n",
       "  12,\n",
       "  260,\n",
       "  8,\n",
       "  31,\n",
       "  15,\n",
       "  64],\n",
       " [18,\n",
       "  11,\n",
       "  5,\n",
       "  31,\n",
       "  9,\n",
       "  124,\n",
       "  125,\n",
       "  126,\n",
       "  259,\n",
       "  103,\n",
       "  20,\n",
       "  35,\n",
       "  30,\n",
       "  13,\n",
       "  56,\n",
       "  66,\n",
       "  12,\n",
       "  260,\n",
       "  8,\n",
       "  31,\n",
       "  15,\n",
       "  64,\n",
       "  7],\n",
       " [18,\n",
       "  11,\n",
       "  5,\n",
       "  31,\n",
       "  9,\n",
       "  124,\n",
       "  125,\n",
       "  126,\n",
       "  259,\n",
       "  103,\n",
       "  20,\n",
       "  35,\n",
       "  30,\n",
       "  13,\n",
       "  56,\n",
       "  66,\n",
       "  12,\n",
       "  260,\n",
       "  8,\n",
       "  31,\n",
       "  15,\n",
       "  64,\n",
       "  7,\n",
       "  1],\n",
       " [18,\n",
       "  11,\n",
       "  5,\n",
       "  31,\n",
       "  9,\n",
       "  124,\n",
       "  125,\n",
       "  126,\n",
       "  259,\n",
       "  103,\n",
       "  20,\n",
       "  35,\n",
       "  30,\n",
       "  13,\n",
       "  56,\n",
       "  66,\n",
       "  12,\n",
       "  260,\n",
       "  8,\n",
       "  31,\n",
       "  15,\n",
       "  64,\n",
       "  7,\n",
       "  1,\n",
       "  261],\n",
       " [18,\n",
       "  11,\n",
       "  5,\n",
       "  31,\n",
       "  9,\n",
       "  124,\n",
       "  125,\n",
       "  126,\n",
       "  259,\n",
       "  103,\n",
       "  20,\n",
       "  35,\n",
       "  30,\n",
       "  13,\n",
       "  56,\n",
       "  66,\n",
       "  12,\n",
       "  260,\n",
       "  8,\n",
       "  31,\n",
       "  15,\n",
       "  64,\n",
       "  7,\n",
       "  1,\n",
       "  261,\n",
       "  262],\n",
       " [263, 264],\n",
       " [263, 264, 2],\n",
       " [263, 264, 2, 3],\n",
       " [263, 264, 2, 3, 265],\n",
       " [263, 264, 2, 3, 265, 127],\n",
       " [263, 264, 2, 3, 265, 127, 128],\n",
       " [266, 8],\n",
       " [266, 8, 1],\n",
       " [266, 8, 1, 267],\n",
       " [266, 8, 1, 267, 268],\n",
       " [266, 8, 1, 267, 268, 29],\n",
       " [266, 8, 1, 267, 268, 29, 1],\n",
       " [266, 8, 1, 267, 268, 29, 1, 80],\n",
       " [266, 8, 1, 267, 268, 29, 1, 80, 6],\n",
       " [266, 8, 1, 267, 268, 29, 1, 80, 6, 269],\n",
       " [266, 8, 1, 267, 268, 29, 1, 80, 6, 269, 270],\n",
       " [266, 8, 1, 267, 268, 29, 1, 80, 6, 269, 270, 127],\n",
       " [266, 8, 1, 267, 268, 29, 1, 80, 6, 269, 270, 127, 128],\n",
       " [266, 8, 1, 267, 268, 29, 1, 80, 6, 269, 270, 127, 128, 25],\n",
       " [266, 8, 1, 267, 268, 29, 1, 80, 6, 269, 270, 127, 128, 25, 68],\n",
       " [266, 8, 1, 267, 268, 29, 1, 80, 6, 269, 270, 127, 128, 25, 68, 271],\n",
       " [41, 5],\n",
       " [41, 5, 4],\n",
       " [41, 5, 4, 39],\n",
       " [41, 5, 4, 39, 70],\n",
       " [41, 5, 4, 39, 70, 26],\n",
       " [41, 5, 4, 39, 70, 26, 4],\n",
       " [41, 5, 4, 39, 70, 26, 4, 46],\n",
       " [41, 5, 4, 39, 70, 26, 4, 46, 272],\n",
       " [41, 5, 4, 39, 70, 26, 4, 46, 272, 35],\n",
       " [41, 5, 4, 39, 70, 26, 4, 46, 272, 35, 71],\n",
       " [41, 5, 4, 39, 70, 26, 4, 46, 272, 35, 71, 13],\n",
       " [11, 5],\n",
       " [11, 5, 48],\n",
       " [11, 5, 48, 2],\n",
       " [11, 5, 48, 2, 3],\n",
       " [11, 5, 48, 2, 3, 49],\n",
       " [11, 5, 48, 2, 3, 49, 28],\n",
       " [11, 5, 48, 2, 3, 49, 28, 273],\n",
       " [11, 5, 48, 2, 3, 49, 28, 273, 113],\n",
       " [11, 5, 48, 2, 3, 49, 28, 273, 113, 27],\n",
       " [11, 5, 48, 2, 3, 49, 28, 273, 113, 27, 20],\n",
       " [11, 5, 48, 2, 3, 49, 28, 273, 113, 27, 20, 109],\n",
       " [11, 5, 48, 2, 3, 49, 28, 273, 113, 27, 20, 109, 110],\n",
       " [11, 5, 48, 2, 3, 49, 28, 273, 113, 27, 20, 109, 110, 111],\n",
       " [11, 5, 48, 2, 3, 49, 28, 273, 113, 27, 20, 109, 110, 111, 112],\n",
       " [26, 4],\n",
       " [26, 4, 13],\n",
       " [26, 4, 13, 2],\n",
       " [26, 4, 13, 2, 3],\n",
       " [26, 4, 13, 2, 3, 129],\n",
       " [26, 4, 13, 2, 3, 129, 5],\n",
       " [26, 4, 13, 2, 3, 129, 5, 4],\n",
       " [26, 4, 13, 2, 3, 129, 5, 4, 274],\n",
       " [26, 4, 13, 2, 3, 129, 5, 4, 274, 37],\n",
       " [26, 4, 13, 2, 3, 129, 5, 4, 274, 37, 1],\n",
       " [26, 4, 13, 2, 3, 129, 5, 4, 274, 37, 1, 76],\n",
       " [26, 4, 13, 2, 3, 129, 5, 4, 274, 37, 1, 76, 14],\n",
       " [18, 56],\n",
       " [18, 56, 66],\n",
       " [18, 56, 66, 12],\n",
       " [18, 56, 66, 12, 275],\n",
       " [18, 56, 66, 12, 275, 8],\n",
       " [18, 56, 66, 12, 275, 8, 130],\n",
       " [18, 56, 66, 12, 275, 8, 130, 30],\n",
       " [18, 56, 66, 12, 275, 8, 130, 30, 13],\n",
       " [18, 56, 66, 12, 275, 8, 130, 30, 13, 6],\n",
       " [18, 56, 66, 12, 275, 8, 130, 30, 13, 6, 33],\n",
       " [18, 56, 66, 12, 275, 8, 130, 30, 13, 6, 33, 40],\n",
       " [18, 56, 66, 12, 275, 8, 130, 30, 13, 6, 33, 40, 8],\n",
       " [18, 56, 66, 12, 275, 8, 130, 30, 13, 6, 33, 40, 8, 276],\n",
       " [18, 56, 66, 12, 275, 8, 130, 30, 13, 6, 33, 40, 8, 276, 30],\n",
       " [18, 56, 66, 12, 275, 8, 130, 30, 13, 6, 33, 40, 8, 276, 30, 37],\n",
       " [4, 36],\n",
       " [4, 36, 117],\n",
       " [4, 36, 117, 118],\n",
       " [4, 36, 117, 118, 1],\n",
       " [4, 36, 117, 118, 1, 119],\n",
       " [4, 36, 117, 118, 1, 119, 6],\n",
       " [4, 36, 117, 118, 1, 119, 6, 4],\n",
       " [4, 36, 117, 118, 1, 119, 6, 4, 36],\n",
       " [4, 36, 117, 118, 1, 119, 6, 4, 36, 68],\n",
       " [4, 36, 117, 118, 1, 119, 6, 4, 36, 68, 120],\n",
       " [4, 36, 117, 118, 1, 119, 6, 4, 36, 68, 120, 8],\n",
       " [4, 36, 117, 118, 1, 119, 6, 4, 36, 68, 120, 8, 50],\n",
       " [4, 36, 117, 118, 1, 119, 6, 4, 36, 68, 120, 8, 50, 277],\n",
       " [4, 36, 117, 118, 1, 119, 6, 4, 36, 68, 120, 8, 50, 277, 28],\n",
       " [4, 36, 117, 118, 1, 119, 6, 4, 36, 68, 120, 8, 50, 277, 28, 69],\n",
       " [4, 36, 117, 118, 1, 119, 6, 4, 36, 68, 120, 8, 50, 277, 28, 69, 10],\n",
       " [4, 36, 117, 118, 1, 119, 6, 4, 36, 68, 120, 8, 50, 277, 28, 69, 10, 63],\n",
       " [4, 36, 117, 118, 1, 119, 6, 4, 36, 68, 120, 8, 50, 277, 28, 69, 10, 63, 4],\n",
       " [4,\n",
       "  36,\n",
       "  117,\n",
       "  118,\n",
       "  1,\n",
       "  119,\n",
       "  6,\n",
       "  4,\n",
       "  36,\n",
       "  68,\n",
       "  120,\n",
       "  8,\n",
       "  50,\n",
       "  277,\n",
       "  28,\n",
       "  69,\n",
       "  10,\n",
       "  63,\n",
       "  4,\n",
       "  34],\n",
       " [48, 2],\n",
       " [48, 2, 3],\n",
       " [48, 2, 3, 49],\n",
       " [48, 2, 3, 49, 28],\n",
       " [48, 2, 3, 49, 28, 7],\n",
       " [48, 2, 3, 49, 28, 7, 278],\n",
       " [48, 2, 3, 49, 28, 7, 278, 24],\n",
       " [48, 2, 3, 49, 28, 7, 278, 24, 121],\n",
       " [48, 2, 3, 49, 28, 7, 278, 24, 121, 50],\n",
       " [48, 2, 3, 49, 28, 7, 278, 24, 121, 50, 59],\n",
       " [279, 60],\n",
       " [279, 60, 6],\n",
       " [279, 60, 6, 70],\n",
       " [279, 60, 6, 70, 61],\n",
       " [10, 12],\n",
       " [10, 12, 1],\n",
       " [10, 12, 1, 280],\n",
       " [10, 12, 1, 280, 8],\n",
       " [10, 12, 1, 280, 8, 39],\n",
       " [10, 12, 1, 280, 8, 39, 9],\n",
       " [10, 12, 1, 280, 8, 39, 9, 131],\n",
       " [131, 12],\n",
       " [131, 12, 281],\n",
       " [131, 12, 281, 282],\n",
       " [131, 12, 281, 282, 95],\n",
       " [131, 12, 281, 282, 95, 2],\n",
       " [131, 12, 281, 282, 95, 2, 40],\n",
       " [131, 12, 281, 282, 95, 2, 40, 19],\n",
       " [131, 12, 281, 282, 95, 2, 40, 19, 38],\n",
       " [131, 12, 281, 282, 95, 2, 40, 19, 38, 1],\n",
       " [131, 12, 281, 282, 95, 2, 40, 19, 38, 1, 44],\n",
       " [131, 12, 281, 282, 95, 2, 40, 19, 38, 1, 44, 27],\n",
       " [131, 12, 281, 282, 95, 2, 40, 19, 38, 1, 44, 27, 7],\n",
       " [131, 12, 281, 282, 95, 2, 40, 19, 38, 1, 44, 27, 7, 115],\n",
       " [131, 12, 281, 282, 95, 2, 40, 19, 38, 1, 44, 27, 7, 115, 21],\n",
       " [131, 12, 281, 282, 95, 2, 40, 19, 38, 1, 44, 27, 7, 115, 21, 45],\n",
       " [131, 12, 281, 282, 95, 2, 40, 19, 38, 1, 44, 27, 7, 115, 21, 45, 8],\n",
       " [131, 12, 281, 282, 95, 2, 40, 19, 38, 1, 44, 27, 7, 115, 21, 45, 8, 33],\n",
       " [131, 12, 281, 282, 95, 2, 40, 19, 38, 1, 44, 27, 7, 115, 21, 45, 8, 33, 283],\n",
       " [131,\n",
       "  12,\n",
       "  281,\n",
       "  282,\n",
       "  95,\n",
       "  2,\n",
       "  40,\n",
       "  19,\n",
       "  38,\n",
       "  1,\n",
       "  44,\n",
       "  27,\n",
       "  7,\n",
       "  115,\n",
       "  21,\n",
       "  45,\n",
       "  8,\n",
       "  33,\n",
       "  283,\n",
       "  19],\n",
       " [4, 36],\n",
       " [4, 36, 284],\n",
       " [4, 36, 284, 129],\n",
       " [4, 36, 284, 129, 45],\n",
       " [4, 36, 284, 129, 45, 5],\n",
       " [4, 36, 284, 129, 45, 5, 4],\n",
       " [4, 36, 284, 129, 45, 5, 4, 285],\n",
       " [4, 36, 284, 129, 45, 5, 4, 285, 90],\n",
       " [4, 36, 284, 129, 45, 5, 4, 285, 90, 21],\n",
       " [4, 36, 284, 129, 45, 5, 4, 285, 90, 21, 132],\n",
       " [4, 36, 284, 129, 45, 5, 4, 285, 90, 21, 132, 14],\n",
       " [130, 30],\n",
       " [130, 30, 13],\n",
       " [130, 30, 13, 114],\n",
       " [130, 30, 13, 114, 1],\n",
       " [130, 30, 13, 114, 1, 2],\n",
       " [130, 30, 13, 114, 1, 2, 40],\n",
       " [130, 30, 13, 114, 1, 2, 40, 19],\n",
       " [130, 30, 13, 114, 1, 2, 40, 19, 6],\n",
       " [130, 30, 13, 114, 1, 2, 40, 19, 6, 286],\n",
       " [130, 30, 13, 114, 1, 2, 40, 19, 6, 286, 1],\n",
       " [130, 30, 13, 114, 1, 2, 40, 19, 6, 286, 1, 14],\n",
       " [130, 30, 13, 114, 1, 2, 40, 19, 6, 286, 1, 14, 11],\n",
       " [130, 30, 13, 114, 1, 2, 40, 19, 6, 286, 1, 14, 11, 132],\n",
       " [10, 287],\n",
       " [10, 287, 1],\n",
       " [10, 287, 1, 133],\n",
       " [10, 287, 1, 133, 72],\n",
       " [10, 287, 1, 133, 72, 19],\n",
       " [10, 287, 1, 133, 72, 19, 288],\n",
       " [133, 72],\n",
       " [133, 72, 19],\n",
       " [133, 72, 19, 289],\n",
       " [133, 72, 19, 289, 9],\n",
       " [133, 72, 19, 289, 9, 290],\n",
       " [133, 72, 19, 289, 9, 290, 72],\n",
       " [133, 72, 19, 289, 9, 290, 72, 37],\n",
       " [133, 72, 19, 289, 9, 290, 72, 37, 24],\n",
       " [133, 72, 19, 289, 9, 290, 72, 37, 24, 291],\n",
       " [133, 72, 19, 289, 9, 290, 72, 37, 24, 291, 50],\n",
       " [133, 72, 19, 289, 9, 290, 72, 37, 24, 291, 50, 8],\n",
       " [133, 72, 19, 289, 9, 290, 72, 37, 24, 291, 50, 8, 14],\n",
       " [133, 72, 19, 289, 9, 290, 72, 37, 24, 291, 50, 8, 14, 81],\n",
       " [133, 72, 19, 289, 9, 290, 72, 37, 24, 291, 50, 8, 14, 81, 87],\n",
       " [133, 72, 19, 289, 9, 290, 72, 37, 24, 291, 50, 8, 14, 81, 87, 6],\n",
       " [133, 72, 19, 289, 9, 290, 72, 37, 24, 291, 50, 8, 14, 81, 87, 6, 292],\n",
       " [133, 72, 19, 289, 9, 290, 72, 37, 24, 291, 50, 8, 14, 81, 87, 6, 292, 293]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5708a8",
   "metadata": {},
   "source": [
    "## Lets make data structured - using padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58ef2268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "max_len = max([len(x) for x in input_sequences])\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b1664d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for zero padding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "padded_input_sequences = pad_sequences(input_sequences, maxlen = max_len, padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "140dfb6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,   0,  51,   2],\n",
       "       [  0,   0,   0, ...,  51,   2,   3],\n",
       "       [  0,   0,   0, ...,   0,  10,  12],\n",
       "       ...,\n",
       "       [  0,   0,   0, ...,  81,  87,   6],\n",
       "       [  0,   0,   0, ...,  87,   6, 292],\n",
       "       [  0,   0,   0, ...,   6, 292, 293]], dtype=int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_input_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca507be",
   "metadata": {},
   "source": [
    "## Splitting of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc462dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = padded_input_sequences[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "600b6363",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = padded_input_sequences[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac90daf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(771, 25)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83d26f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(771,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed05403d",
   "metadata": {},
   "source": [
    "## Tranforming output using OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13ceb206",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y = to_categorical(y,num_classes=294)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2637b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(771, 294)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5024b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5054416d",
   "metadata": {},
   "source": [
    "# GRU APPLICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5eda3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding ,GRU, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03025831",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shinchan/anaconda3/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=294, output_dim=100, input_length=25))  # Adjust input_length to 25\n",
    "# model.add(LSTM(150, return_sequences=True))  # First LSTM layer\n",
    "model.add(GRU(75))  # Second LSTM layer\n",
    "model.add(Dense(294, activation='softmax'))  # Output layer with 294 units\n",
    "# Build the model by specifying an input shape\n",
    "model.build(input_shape=(None, 25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd3a0e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a1eb1ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
       "\n",
       " embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">29,400</span> \n",
       "\n",
       " gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">39,825</span> \n",
       "\n",
       " dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">294</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">22,344</span> \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " embedding (\u001b[38;5;33mEmbedding\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m100\u001b[0m)                \u001b[38;5;34m29,400\u001b[0m \n",
       "\n",
       " gru (\u001b[38;5;33mGRU\u001b[0m)                        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m)                     \u001b[38;5;34m39,825\u001b[0m \n",
       "\n",
       " dense (\u001b[38;5;33mDense\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m294\u001b[0m)                    \u001b[38;5;34m22,344\u001b[0m \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">91,569</span> (357.69 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m91,569\u001b[0m (357.69 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">91,569</span> (357.69 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m91,569\u001b[0m (357.69 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7991c11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.0253 - loss: 5.6745\n",
      "Epoch 2/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.0585 - loss: 5.4251\n",
      "Epoch 3/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.0702 - loss: 5.0319\n",
      "Epoch 4/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.0816 - loss: 4.9663\n",
      "Epoch 5/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.0913 - loss: 4.8964\n",
      "Epoch 6/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.1145 - loss: 4.7390\n",
      "Epoch 7/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.1386 - loss: 4.5937\n",
      "Epoch 8/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 0.1534 - loss: 4.4752\n",
      "Epoch 9/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.1647 - loss: 4.2650\n",
      "Epoch 10/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.2042 - loss: 4.0483\n",
      "Epoch 11/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.2400 - loss: 3.9155\n",
      "Epoch 12/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.2564 - loss: 3.7744\n",
      "Epoch 13/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.2679 - loss: 3.5051\n",
      "Epoch 14/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.3168 - loss: 3.4419\n",
      "Epoch 15/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.3746 - loss: 3.1652\n",
      "Epoch 16/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.3668 - loss: 3.0654\n",
      "Epoch 17/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 104ms/step - accuracy: 0.3830 - loss: 2.9300\n",
      "Epoch 18/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.3837 - loss: 2.8778\n",
      "Epoch 19/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.4485 - loss: 2.5669\n",
      "Epoch 20/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - accuracy: 0.4380 - loss: 2.5676\n",
      "Epoch 21/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.4641 - loss: 2.3428\n",
      "Epoch 22/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.5040 - loss: 2.2326\n",
      "Epoch 23/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.5504 - loss: 2.0560\n",
      "Epoch 24/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.5894 - loss: 1.9562\n",
      "Epoch 25/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.5847 - loss: 1.9338\n",
      "Epoch 26/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 0.6161 - loss: 1.7921\n",
      "Epoch 27/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.6493 - loss: 1.6770\n",
      "Epoch 28/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.6556 - loss: 1.6698\n",
      "Epoch 29/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.7189 - loss: 1.4565\n",
      "Epoch 30/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.7263 - loss: 1.4496\n",
      "Epoch 31/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.7319 - loss: 1.4477\n",
      "Epoch 32/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 0.7737 - loss: 1.2634\n",
      "Epoch 33/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 0.7780 - loss: 1.2524\n",
      "Epoch 34/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.8029 - loss: 1.1601\n",
      "Epoch 35/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.8180 - loss: 1.0786\n",
      "Epoch 36/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.8078 - loss: 1.0498\n",
      "Epoch 37/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.8415 - loss: 0.9514\n",
      "Epoch 38/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.8284 - loss: 0.9546\n",
      "Epoch 39/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.8485 - loss: 0.8975\n",
      "Epoch 40/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.8443 - loss: 0.8580\n",
      "Epoch 41/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.8728 - loss: 0.7772\n",
      "Epoch 42/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.8735 - loss: 0.7834\n",
      "Epoch 43/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8782 - loss: 0.7734\n",
      "Epoch 44/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.8787 - loss: 0.7301\n",
      "Epoch 45/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.8915 - loss: 0.7022\n",
      "Epoch 46/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9082 - loss: 0.6261\n",
      "Epoch 47/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9019 - loss: 0.6346\n",
      "Epoch 48/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9170 - loss: 0.5872\n",
      "Epoch 49/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9264 - loss: 0.5598\n",
      "Epoch 50/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9017 - loss: 0.5753\n",
      "Epoch 51/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9178 - loss: 0.5109\n",
      "Epoch 52/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9192 - loss: 0.5043\n",
      "Epoch 53/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.9171 - loss: 0.5185\n",
      "Epoch 54/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.9195 - loss: 0.4876\n",
      "Epoch 55/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9137 - loss: 0.4998\n",
      "Epoch 56/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.9201 - loss: 0.4377\n",
      "Epoch 57/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9363 - loss: 0.4371\n",
      "Epoch 58/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.9320 - loss: 0.4281\n",
      "Epoch 59/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.9365 - loss: 0.3992\n",
      "Epoch 60/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.9370 - loss: 0.3760\n",
      "Epoch 61/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.9371 - loss: 0.3785\n",
      "Epoch 62/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9333 - loss: 0.3883\n",
      "Epoch 63/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.9388 - loss: 0.3732\n",
      "Epoch 64/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.9333 - loss: 0.3607\n",
      "Epoch 65/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.9294 - loss: 0.3601\n",
      "Epoch 66/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9413 - loss: 0.3369\n",
      "Epoch 67/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9474 - loss: 0.3111\n",
      "Epoch 68/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9420 - loss: 0.3111\n",
      "Epoch 69/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9439 - loss: 0.3009\n",
      "Epoch 70/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9295 - loss: 0.3128\n",
      "Epoch 71/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9298 - loss: 0.3080\n",
      "Epoch 72/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9313 - loss: 0.3099\n",
      "Epoch 73/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9342 - loss: 0.3003\n",
      "Epoch 74/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.9406 - loss: 0.2675\n",
      "Epoch 75/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9494 - loss: 0.2653\n",
      "Epoch 76/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.9347 - loss: 0.2745\n",
      "Epoch 77/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9466 - loss: 0.2446\n",
      "Epoch 78/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9546 - loss: 0.2315\n",
      "Epoch 79/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9299 - loss: 0.2610\n",
      "Epoch 80/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9358 - loss: 0.2323\n",
      "Epoch 81/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.9447 - loss: 0.2463\n",
      "Epoch 82/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9421 - loss: 0.2449\n",
      "Epoch 83/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9367 - loss: 0.2488\n",
      "Epoch 84/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9401 - loss: 0.2353\n",
      "Epoch 85/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9407 - loss: 0.2312\n",
      "Epoch 86/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.9365 - loss: 0.2242\n",
      "Epoch 87/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.9539 - loss: 0.2030\n",
      "Epoch 88/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9603 - loss: 0.1866\n",
      "Epoch 89/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9452 - loss: 0.2108\n",
      "Epoch 90/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.9450 - loss: 0.1922\n",
      "Epoch 91/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9412 - loss: 0.2004\n",
      "Epoch 92/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9494 - loss: 0.1988\n",
      "Epoch 93/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9517 - loss: 0.1956\n",
      "Epoch 94/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.9424 - loss: 0.2101\n",
      "Epoch 95/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9311 - loss: 0.2192\n",
      "Epoch 96/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9499 - loss: 0.1890\n",
      "Epoch 97/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9545 - loss: 0.1629\n",
      "Epoch 98/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9570 - loss: 0.1815\n",
      "Epoch 99/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9526 - loss: 0.1721\n",
      "Epoch 100/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9544 - loss: 0.1720\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fe428085840>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9781e10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "the entrance fee for\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "the entrance fee for disney\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "the entrance fee for disney world\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "the entrance fee for disney world in\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "the entrance fee for disney world in 2023\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "the entrance fee for disney world in 2023 which\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "the entrance fee for disney world in 2023 which often\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "the entrance fee for disney world in 2023 which often come\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "the entrance fee for disney world in 2023 which often come with\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "the entrance fee for disney world in 2023 which often come with discounts\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "the entrance fee for disney world in 2023 which often come with discounts discounts\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "the entrance fee for disney world in 2023 which often come with discounts discounts discounts\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "text = \"the entrance fee\"\n",
    "\n",
    "for i in range(12):\n",
    "  # tokenize\n",
    "  token_text = tokenizer.texts_to_sequences([text])[0]\n",
    "  # padding\n",
    "  padded_token_text = pad_sequences([token_text], maxlen=25, padding='pre')\n",
    "  # predict\n",
    "  pos = np.argmax(model.predict(padded_token_text))\n",
    "\n",
    "  for word,index in tokenizer.word_index.items():\n",
    "    if index == pos:\n",
    "      text = text + \" \" + word\n",
    "      print(text)\n",
    "      time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c302ae1e",
   "metadata": {},
   "source": [
    "# LSTM APPLICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "956858f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "03b26045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=294, output_dim=100, input_length=25))  # Adjust input_length to 25\n",
    "# model.add(LSTM(150, return_sequences=True))  # First LSTM layer\n",
    "model.add(LSTM(100))  # Second LSTM layer\n",
    "model.add(Dense(294, activation='softmax'))  # Output layer with 294 units\n",
    "# Build the model by specifying an input shape\n",
    "model.build(input_shape=(None, 25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c1e1e760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "14e6e738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
       "\n",
       " embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">29,400</span> \n",
       "\n",
       " lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">80,400</span> \n",
       "\n",
       " dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">294</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">29,694</span> \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m100\u001b[0m)                \u001b[38;5;34m29,400\u001b[0m \n",
       "\n",
       " lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                    \u001b[38;5;34m80,400\u001b[0m \n",
       "\n",
       " dense_2 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m294\u001b[0m)                    \u001b[38;5;34m29,694\u001b[0m \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">139,494</span> (544.90 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m139,494\u001b[0m (544.90 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">139,494</span> (544.90 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m139,494\u001b[0m (544.90 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4a261a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.0359 - loss: 5.6528\n",
      "Epoch 2/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.0482 - loss: 5.2023\n",
      "Epoch 3/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.0324 - loss: 5.0962\n",
      "Epoch 4/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.0723 - loss: 5.0571\n",
      "Epoch 5/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.0898 - loss: 5.0281\n",
      "Epoch 6/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.0999 - loss: 4.9262\n",
      "Epoch 7/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.1018 - loss: 4.7914\n",
      "Epoch 8/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.1280 - loss: 4.6756\n",
      "Epoch 9/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.1157 - loss: 4.6413\n",
      "Epoch 10/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.1629 - loss: 4.3993\n",
      "Epoch 11/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.1719 - loss: 4.3254\n",
      "Epoch 12/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.1787 - loss: 4.2369\n",
      "Epoch 13/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.1906 - loss: 4.0849\n",
      "Epoch 14/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 0.1831 - loss: 4.0118\n",
      "Epoch 15/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.2077 - loss: 3.8151\n",
      "Epoch 16/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.2128 - loss: 3.7763\n",
      "Epoch 17/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.2139 - loss: 3.7242\n",
      "Epoch 18/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.2436 - loss: 3.5418\n",
      "Epoch 19/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.2701 - loss: 3.4331\n",
      "Epoch 20/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.2848 - loss: 3.3387\n",
      "Epoch 21/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 0.2989 - loss: 3.2321\n",
      "Epoch 22/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - accuracy: 0.3227 - loss: 3.1957\n",
      "Epoch 23/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.3368 - loss: 3.0212\n",
      "Epoch 24/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.3873 - loss: 2.8803\n",
      "Epoch 25/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.3937 - loss: 2.7850\n",
      "Epoch 26/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.4031 - loss: 2.7540\n",
      "Epoch 27/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.4595 - loss: 2.6138\n",
      "Epoch 28/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - accuracy: 0.4566 - loss: 2.5579\n",
      "Epoch 29/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.4998 - loss: 2.4400\n",
      "Epoch 30/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.5279 - loss: 2.4090\n",
      "Epoch 31/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.5208 - loss: 2.3620\n",
      "Epoch 32/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.5753 - loss: 2.2294\n",
      "Epoch 33/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.5897 - loss: 2.1239\n",
      "Epoch 34/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 0.6014 - loss: 2.0485\n",
      "Epoch 35/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 102ms/step - accuracy: 0.6504 - loss: 1.9760\n",
      "Epoch 36/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.6713 - loss: 1.8144\n",
      "Epoch 37/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.6852 - loss: 1.8106\n",
      "Epoch 38/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - accuracy: 0.7030 - loss: 1.7176\n",
      "Epoch 39/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 113ms/step - accuracy: 0.6800 - loss: 1.7073\n",
      "Epoch 40/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 99ms/step - accuracy: 0.7560 - loss: 1.5498 \n",
      "Epoch 41/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.7492 - loss: 1.5399\n",
      "Epoch 42/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.7856 - loss: 1.4438\n",
      "Epoch 43/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.7566 - loss: 1.4258\n",
      "Epoch 44/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 101ms/step - accuracy: 0.7866 - loss: 1.3593\n",
      "Epoch 45/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.8035 - loss: 1.2921\n",
      "Epoch 46/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.8152 - loss: 1.2675\n",
      "Epoch 47/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.8226 - loss: 1.1767\n",
      "Epoch 48/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.8137 - loss: 1.1801\n",
      "Epoch 49/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.8315 - loss: 1.1245\n",
      "Epoch 50/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 113ms/step - accuracy: 0.8453 - loss: 1.0714\n",
      "Epoch 51/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 105ms/step - accuracy: 0.8400 - loss: 1.0367\n",
      "Epoch 52/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.8737 - loss: 0.9454\n",
      "Epoch 53/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.8629 - loss: 0.9553\n",
      "Epoch 54/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.8669 - loss: 0.9183\n",
      "Epoch 55/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.8769 - loss: 0.8620\n",
      "Epoch 56/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.8646 - loss: 0.8819\n",
      "Epoch 57/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.8821 - loss: 0.8280\n",
      "Epoch 58/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.8700 - loss: 0.8074\n",
      "Epoch 59/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.8959 - loss: 0.7481\n",
      "Epoch 60/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 104ms/step - accuracy: 0.8842 - loss: 0.7436\n",
      "Epoch 61/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9028 - loss: 0.7239\n",
      "Epoch 62/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9183 - loss: 0.6555\n",
      "Epoch 63/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9183 - loss: 0.6415\n",
      "Epoch 64/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 0.9068 - loss: 0.6490\n",
      "Epoch 65/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - accuracy: 0.9253 - loss: 0.6167\n",
      "Epoch 66/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - accuracy: 0.9304 - loss: 0.5892\n",
      "Epoch 67/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9153 - loss: 0.6012\n",
      "Epoch 68/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.9179 - loss: 0.5935\n",
      "Epoch 69/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.9392 - loss: 0.5324\n",
      "Epoch 70/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9328 - loss: 0.5384\n",
      "Epoch 71/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - accuracy: 0.9236 - loss: 0.5307\n",
      "Epoch 72/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9361 - loss: 0.4904\n",
      "Epoch 73/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9528 - loss: 0.4477\n",
      "Epoch 74/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.9417 - loss: 0.4818\n",
      "Epoch 75/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - accuracy: 0.9375 - loss: 0.4602\n",
      "Epoch 76/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.9413 - loss: 0.4400\n",
      "Epoch 77/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9497 - loss: 0.4172\n",
      "Epoch 78/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.9421 - loss: 0.4146\n",
      "Epoch 79/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 0.9384 - loss: 0.4076\n",
      "Epoch 80/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 95ms/step - accuracy: 0.9548 - loss: 0.3698\n",
      "Epoch 81/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.9533 - loss: 0.3646\n",
      "Epoch 82/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.9463 - loss: 0.3959\n",
      "Epoch 83/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9350 - loss: 0.3993\n",
      "Epoch 84/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9495 - loss: 0.3538\n",
      "Epoch 85/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 102ms/step - accuracy: 0.9387 - loss: 0.3705\n",
      "Epoch 86/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - accuracy: 0.9471 - loss: 0.3268\n",
      "Epoch 87/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.9488 - loss: 0.3387\n",
      "Epoch 88/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.9451 - loss: 0.3353\n",
      "Epoch 89/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.9414 - loss: 0.3125\n",
      "Epoch 90/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.9568 - loss: 0.3137\n",
      "Epoch 91/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.9501 - loss: 0.2992\n",
      "Epoch 92/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 106ms/step - accuracy: 0.9483 - loss: 0.2919\n",
      "Epoch 93/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.9575 - loss: 0.2745\n",
      "Epoch 94/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9534 - loss: 0.2910\n",
      "Epoch 95/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9591 - loss: 0.2681\n",
      "Epoch 96/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.9613 - loss: 0.2658\n",
      "Epoch 97/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 117ms/step - accuracy: 0.9465 - loss: 0.2746\n",
      "Epoch 98/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.9442 - loss: 0.2613\n",
      "Epoch 99/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9531 - loss: 0.2653\n",
      "Epoch 100/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.9508 - loss: 0.2550\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fae2cda8d00>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e881309a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "the entrance fee for\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "the entrance fee for disney\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "the entrance fee for disney world\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "the entrance fee for disney world can\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "the entrance fee for disney world can we\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "the entrance fee for disney world can we buy\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "the entrance fee for disney world can we buy them\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "the entrance fee for disney world can we buy them on\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "the entrance fee for disney world can we buy them on youtube\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "the entrance fee for disney world can we buy them on youtube or\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "text = \"the entrance fee\"\n",
    "\n",
    "for i in range(10):\n",
    "  # tokenize\n",
    "  token_text = tokenizer.texts_to_sequences([text])[0]\n",
    "  # padding\n",
    "  padded_token_text = pad_sequences([token_text], maxlen=25, padding='pre')\n",
    "  # predict\n",
    "  pos = np.argmax(model.predict(padded_token_text))\n",
    "\n",
    "  for word,index in tokenizer.word_index.items():\n",
    "    if index == pos:\n",
    "      text = text + \" \" + word\n",
    "      print(text)\n",
    "      time.sleep(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
